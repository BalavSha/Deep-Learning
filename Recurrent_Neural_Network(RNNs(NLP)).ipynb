{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalavSha/Deep-Learning/blob/main/Recurrent_Neural_Network(RNNs(NLP)).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Recurrent Neural Network(RNNs)** </center>\n",
        "\n",
        "--> ANNs to handle sequential data"
      ],
      "metadata": {
        "id": "PCMo8n4AllQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to develop RNN models that can do the following:\n",
        "\n",
        "\n",
        "*   Handle variable-length input sequences\n",
        "\n",
        "*   Track long-term dependencies in the data\n",
        "\n",
        "*   Maintain information about the sequence's order\n",
        "\n",
        "*   Share parameters across the entirety of the sequence"
      ],
      "metadata": {
        "id": "S30OSyEWgPtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training an ANN for Sequential Data - Nvidia Stock prediction**\n",
        "\n",
        "\n",
        "*   **target variable** -> Price of stock in a given day\n",
        "*   **features** -> Price of a stock in a previous 60 days"
      ],
      "metadata": {
        "id": "oWP4wsGDg5f4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx6PBFOKlIrY"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Nvidia Stock Data:"
      ],
      "metadata": {
        "id": "vj7VUSq1By_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/PacktWorkshops/The-TensorFlow-Workshop/master/Chapter09/Datasets/NVDA.csv\")\n",
        "\n",
        "# display first 5 rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lnKpupIDBgYZ",
        "outputId": "f54b83ef-0c5e-439b-8f34-24252ffb4888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High    Low      Close  Adj Close   Volume\n",
              "0  2015-07-22  19.650000  19.650000  19.17  19.410000  18.851749  8911800\n",
              "1  2015-07-23  19.450001  19.940001  19.41  19.650000  19.084845  4247900\n",
              "2  2015-07-24  19.790001  19.809999  19.34  19.420000  18.861464  4721100\n",
              "3  2015-07-27  19.250000  19.530001  19.09  19.309999  18.754622  4810500\n",
              "4  2015-07-28  19.360001  19.860001  19.16  19.730000  19.162542  4957700"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52428d64-ae4d-4684-94f9-83f91d36cefb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-07-22</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>19.17</td>\n",
              "      <td>19.410000</td>\n",
              "      <td>18.851749</td>\n",
              "      <td>8911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-07-23</td>\n",
              "      <td>19.450001</td>\n",
              "      <td>19.940001</td>\n",
              "      <td>19.41</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>19.084845</td>\n",
              "      <td>4247900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-07-24</td>\n",
              "      <td>19.790001</td>\n",
              "      <td>19.809999</td>\n",
              "      <td>19.34</td>\n",
              "      <td>19.420000</td>\n",
              "      <td>18.861464</td>\n",
              "      <td>4721100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-07-27</td>\n",
              "      <td>19.250000</td>\n",
              "      <td>19.530001</td>\n",
              "      <td>19.09</td>\n",
              "      <td>19.309999</td>\n",
              "      <td>18.754622</td>\n",
              "      <td>4810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-07-28</td>\n",
              "      <td>19.360001</td>\n",
              "      <td>19.860001</td>\n",
              "      <td>19.16</td>\n",
              "      <td>19.730000</td>\n",
              "      <td>19.162542</td>\n",
              "      <td>4957700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52428d64-ae4d-4684-94f9-83f91d36cefb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52428d64-ae4d-4684-94f9-83f91d36cefb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52428d64-ae4d-4684-94f9-83f91d36cefb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Split the dataset into training and test sets:"
      ],
      "metadata": {
        "id": "bQqUlaOzCmto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  use data before \"2019-01-01\" as training set\n",
        "data_training = data[data[\"Date\"] < \"2019-01-01\"].copy()\n",
        "\n",
        "# use data after \"2019-01-01\" as testing set\n",
        "data_test = data[data[\"Date\"] >= \"2019-01-01\"].copy()"
      ],
      "metadata": {
        "id": "M__7FrnkCYSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Open       High    Low      Close   Volume\n",
              "0  19.650000  19.650000  19.17  19.410000  8911800\n",
              "1  19.450001  19.940001  19.41  19.650000  4247900\n",
              "2  19.790001  19.809999  19.34  19.420000  4721100\n",
              "3  19.250000  19.530001  19.09  19.309999  4810500\n",
              "4  19.360001  19.860001  19.16  19.730000  4957700"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9136f307-5d7e-4aa4-9dc9-19fed393fb45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.650000</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>19.17</td>\n",
              "      <td>19.410000</td>\n",
              "      <td>8911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19.450001</td>\n",
              "      <td>19.940001</td>\n",
              "      <td>19.41</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>4247900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.790001</td>\n",
              "      <td>19.809999</td>\n",
              "      <td>19.34</td>\n",
              "      <td>19.420000</td>\n",
              "      <td>4721100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19.250000</td>\n",
              "      <td>19.530001</td>\n",
              "      <td>19.09</td>\n",
              "      <td>19.309999</td>\n",
              "      <td>4810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.360001</td>\n",
              "      <td>19.860001</td>\n",
              "      <td>19.16</td>\n",
              "      <td>19.730000</td>\n",
              "      <td>4957700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9136f307-5d7e-4aa4-9dc9-19fed393fb45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9136f307-5d7e-4aa4-9dc9-19fed393fb45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9136f307-5d7e-4aa4-9dc9-19fed393fb45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# drop the un-necessary columns after splitting\n",
        "training_data = data_training.drop([\"Date\", \"Adj Close\"], axis=1)\n",
        "test_data = data_test.drop([\"Date\", \"Adj Close\"], axis=1)\n",
        "\n",
        "# display the changed dataframe\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "ohlawLgC_lme",
        "outputId": "46542daa-065e-4b7d-f93c-2eccdff8f799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Rescale the training data in a uniform range"
      ],
      "metadata": {
        "collapsed": false,
        "id": "xu91cBeF_lme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# store the column names before rescaling\n",
        "train_cols = training_data.columns\n",
        "test_cols = test_data.columns\n",
        "\n",
        "train_cols"
      ],
      "metadata": {
        "id": "VqmT9BiH_lme",
        "outputId": "9e686b07-8b13-4de3-d2c9-a85b435d7171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# perform the rescaling\n",
        "training_data = scaler.fit_transform(training_data)\n",
        "# training_data = pd.DataFrame(training_data, columns=train_cols)\n",
        "# training_data.head()"
      ],
      "metadata": {
        "id": "dDzuT1oQ_lmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Prepare data from traning and testing"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vdoqwrCJ_lmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "868"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# check the shape of training_data\n",
        "training_data.shape[0]"
      ],
      "metadata": {
        "id": "V_CFRRg6_lmg",
        "outputId": "747b970b-ff9b-4bdb-c428-b543b3eb3fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# split your data into X_train and y_train\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Looping through the range of 60 to the number of rows in training_data\n",
        "for i in range(60, training_data.shape[0]):\n",
        "\n",
        "    # Appending the values of training_data from i-60 to i to X_train\n",
        "    X_train.append(training_data[i-60:i])\n",
        "\n",
        "    # Appending the value of training_data at index i, column 0 to y_train\n",
        "    y_train.append(training_data[i, 0])"
      ],
      "metadata": {
        "id": "Q5PO11rr_lmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (808, 60, 5)\n",
            "y_train: (808,)\n"
          ]
        }
      ],
      "source": [
        "# convert X_train and y_train into NumPy arrays\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "# display the dimension of X_train, y_train\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)"
      ],
      "metadata": {
        "id": "AFPM1T9U_lmg",
        "outputId": "f0398f33-6248-44ba-fc89-224c9d1628c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> As shown above, the prepared training set contains 808 observations with 60 days of data for the five features."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Zgo9y0d1_lmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Transform the data into a 2D matrix with the shape of the sample (the number of samples and the number of features in each sample).<br>\n",
        "##### Stack the features for all 60 days on top of each other to get an output size of (808, 300)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "bdDSVxcw_lmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(808, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# save the shape of X_train\n",
        "X_old_shape = X_train.shape\n",
        "\n",
        "# reshaping X_train to have X_old_shape[0] rows and X_old_shape[1]*X_old_shape[2] columns\n",
        "X_train = X_train.reshape(X_old_shape[0], X_old_shape[1]*X_old_shape[2])\n",
        "\n",
        "# display the reshaped X_train\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "74TcGrdx_lmh",
        "outputId": "e85852b8-061a-4394-d10a-1bcadc584803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Build an ANN model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "g6uo34Sc_lmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout"
      ],
      "metadata": {
        "id": "iDn9z_2G_lmi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# initialize the ANN model\n",
        "regressor_ann = Sequential()"
      ],
      "metadata": {
        "id": "K-Nifj-K_lmi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# add an input layer with input_shape as 300\n",
        "regressor_ann.add(Input(shape = (X_train.shape[1])))\n",
        "\n",
        "# add dense layer with 512 units as output\n",
        "regressor_ann.add(Dense(512, activation=\"relu\"))\n",
        "# add dropout layer to remove 20% of the units during training to prevent overfitting\n",
        "regressor_ann.add(Dropout(0.2))\n",
        "\n",
        "# add another dense layer and Dropout layer\n",
        "regressor_ann.add(Dense(128, activation=\"relu\"))\n",
        "# add another Dropout layer\n",
        "regressor_ann.add(Dropout(0.3))\n",
        "\n",
        "# add another dense and dropout layer\n",
        "regressor_ann.add(Dense(64, activation=\"relu\"))\n",
        "regressor_ann.add(Dropout(0.4))\n",
        "\n",
        "# add another dense and dropout layer\n",
        "regressor_ann.add(Dense(16, activation=\"relu\"))\n",
        "regressor_ann.add(Dropout(0.5))\n",
        "\n",
        "# add final dense layer as output\n",
        "regressor_ann.add(Dense(1))"
      ],
      "metadata": {
        "id": "3Q2YRfLv_lmi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               154112    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229,089\n",
            "Trainable params: 229,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# display of the model architecture\n",
        "regressor_ann.summary()"
      ],
      "metadata": {
        "id": "Vv1KvUzJ_lmi",
        "outputId": "e41761bd-5aaa-48d6-bca0-9d14f25da5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compile the model with optimizer, loss function and accuracy metrics."
      ],
      "metadata": {
        "collapsed": false,
        "id": "zlbmk72o_lmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# compile the model for training\n",
        "regressor_ann.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"mean_squared_error\",\n",
        "    metrics=\"mse\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "j7cbOPg4_lmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Train the ANN model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zhVukk4-_lmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 6s 4ms/step - loss: 0.1787 - mse: 0.1787\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1074 - mse: 0.1074\n",
            "Epoch 3/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0804 - mse: 0.0804\n",
            "Epoch 4/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 5/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 6/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0715 - mse: 0.0715\n",
            "Epoch 7/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 8/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 9/20\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 10/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 11/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 12/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 13/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 14/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 15/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0395 - mse: 0.0395\n",
            "Epoch 16/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0427 - mse: 0.0427\n",
            "Epoch 17/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0397 - mse: 0.0397\n",
            "Epoch 18/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 19/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0376 - mse: 0.0376\n",
            "Epoch 20/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.0371 - mse: 0.0371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50d0047460>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# fit the ANN model to the training data\n",
        "regressor_ann.fit(X_train,\n",
        "                  y_train,\n",
        "                  epochs=20,\n",
        "                  batch_size=32\n",
        "                  )"
      ],
      "metadata": {
        "id": "x9GuwlDw_lmj",
        "outputId": "8963db1c-9f8b-42a3-91d8-450cb03ffd75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center><b>Recurrent Neural Networks(RNN)</b></center>"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CRlybxrf_lmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building an RNN model with an LSTM layer for Nvidia Stock Prediction:**"
      ],
      "metadata": {
        "id": "zbEGY61kHCek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense"
      ],
      "metadata": {
        "id": "N5WudMrRIuGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# Creating a Sequential model\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding a LSTM layer with 50 units, 'relu' activation function,\n",
        "# return_sequences set to True and an input shape of (X_train.shape[1], 5)\n",
        "# This layer will take in the input data and process it using LSTM units\n",
        "regressor.add(LSTM(units=50, activation='relu', return_sequences=True,\n",
        "                   input_shape=(X_train.shape[1], 5)))\n",
        "\n",
        "# Adding a Dropout layer with a rate of 0.2\n",
        "# This layer will randomly drop out 20% of the units in the previous layer\n",
        "# to prevent overfitting\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding another LSTM layer with 60 units and 'relu' activation function\n",
        "# This layer will take in the output from the previous LSTM layer and process it further\n",
        "regressor.add(LSTM(units=60, activation='relu', return_sequences=True))\n",
        "\n",
        "# Adding another Dropout layer with a rate of 0.3\n",
        "# This layer will randomly drop out 30% of the units in the previous layer\n",
        "# to prevent overfitting\n",
        "regressor.add(Dropout(0.3))\n",
        "\n",
        "# Adding another LSTM layer with 80 units and 'relu' activation function\n",
        "# This layer will take in the output from the previous LSTM layer and process it further\n",
        "regressor.add(LSTM(units=80, activation='relu', return_sequences=True))\n",
        "\n",
        "# Adding another Dropout layer with a rate of 0.4\n",
        "# This layer will randomly drop out 40% of the units in the previous layer\n",
        "# to prevent overfitting\n",
        "regressor.add(Dropout(0.4))\n",
        "\n",
        "# Adding another LSTM layer with 120 units and 'relu' activation function\n",
        "# This layer will take in the output from the previous LSTM layer and process it further\n",
        "regressor.add(LSTM(units=120, activation='relu'))\n",
        "\n",
        "# Adding another Dropout layer with a rate of 0.5\n",
        "# This layer will randomly drop out 50% of the units in the previous layer\n",
        "# to prevent overfitting\n",
        "regressor.add(Dropout(0.5))\n",
        "\n",
        "# Adding a Dense layer with 1 unit\n",
        "# This is the output layer that will produce the final prediction\n",
        "regressor.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "dP5PSBqF_lmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56490490-a5a4-404b-94a2-c66d68b736e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view the summary of the model architecture\n",
        "regressor.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU27JferJJpt",
        "outputId": "427d72f6-0111-4fd0-c3bf-2945a4213eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 300, 50)           11200     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 300, 50)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 300, 60)           26640     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 300, 60)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 300, 80)           45120     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 300, 80)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 120)               96480     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 121       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179,561\n",
            "Trainable params: 179,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "SkOpJ0wOKMe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "2cTq6oBWKLGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build an RNN model with Multiple LSTM Layers to Predict Power Consumption:"
      ],
      "metadata": {
        "id": "uojOuMRHKoY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "n9ao6at5LcIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# library for performing rescaling\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "iA4WTyBHKL3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Dataset**"
      ],
      "metadata": {
        "id": "KgpJ9n-aLvtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/PacktWorkshops/The-TensorFlow-Workshop/master/Chapter09/Datasets/household_power_consumption.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O10TlpX9Lr7Q",
        "outputId": "34c9585a-d7ed-4ad0-9e2e-2dfda3c633c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date     Time Global_active_power Global_reactive_power Voltage  \\\n",
              "0  1/1/2007  0:00:00                2.58                 0.136  241.97   \n",
              "1  1/1/2007  0:01:00               2.552                   0.1  241.75   \n",
              "2  1/1/2007  0:02:00                2.55                   0.1  241.64   \n",
              "3  1/1/2007  0:03:00                2.55                   0.1  241.71   \n",
              "4  1/1/2007  0:04:00               2.554                   0.1  241.98   \n",
              "\n",
              "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
              "0             10.6              0              0             0.0  \n",
              "1             10.4              0              0             0.0  \n",
              "2             10.4              0              0             0.0  \n",
              "3             10.4              0              0             0.0  \n",
              "4             10.4              0              0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c1c3b92-3145-4603-90de-9dd4da218e80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>2.58</td>\n",
              "      <td>0.136</td>\n",
              "      <td>241.97</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>0:01:00</td>\n",
              "      <td>2.552</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.75</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>0:02:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.64</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>0:03:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.71</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>0:04:00</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.98</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c1c3b92-3145-4603-90de-9dd4da218e80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c1c3b92-3145-4603-90de-9dd4da218e80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c1c3b92-3145-4603-90de-9dd4da218e80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a new column Datetime by combining Date & Time columns**"
      ],
      "metadata": {
        "id": "nykSuz9BMikR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the column into datetime object with specified format\n",
        "data[\"Date\"] = pd.to_datetime(data[\"Date\"], format=\"%d/%m/%Y\")\n",
        "\n",
        "# create new \"Datetime\" column by combing \"Date\" and \"Time\" columns\n",
        "data[\"Datetime\"] = data[\"Date\"].dt.strftime(\"%Y-%m-%d\") + \" \" + data[\"Time\"]\n",
        "\n",
        "# convert the \"Datetime\" column to datetime object\n",
        "data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VOL5y733L_XB",
        "outputId": "9fc585ff-c391-4a60-e46a-e4dd4a70ecdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date     Time Global_active_power Global_reactive_power Voltage  \\\n",
              "0 2007-01-01  0:00:00                2.58                 0.136  241.97   \n",
              "1 2007-01-01  0:01:00               2.552                   0.1  241.75   \n",
              "2 2007-01-01  0:02:00                2.55                   0.1  241.64   \n",
              "3 2007-01-01  0:03:00                2.55                   0.1  241.71   \n",
              "4 2007-01-01  0:04:00               2.554                   0.1  241.98   \n",
              "\n",
              "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \\\n",
              "0             10.6              0              0             0.0   \n",
              "1             10.4              0              0             0.0   \n",
              "2             10.4              0              0             0.0   \n",
              "3             10.4              0              0             0.0   \n",
              "4             10.4              0              0             0.0   \n",
              "\n",
              "             Datetime  \n",
              "0 2007-01-01 00:00:00  \n",
              "1 2007-01-01 00:01:00  \n",
              "2 2007-01-01 00:02:00  \n",
              "3 2007-01-01 00:03:00  \n",
              "4 2007-01-01 00:04:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-688de055-0fc6-4367-a71d-eb59e18624cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "      <th>Datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>2.58</td>\n",
              "      <td>0.136</td>\n",
              "      <td>241.97</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:01:00</td>\n",
              "      <td>2.552</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.75</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:02:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.64</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:03:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.71</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:04:00</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.98</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:04:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-688de055-0fc6-4367-a71d-eb59e18624cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-688de055-0fc6-4367-a71d-eb59e18624cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-688de055-0fc6-4367-a71d-eb59e18624cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the dataframe in ascending order using the \"Datetime\" column\n",
        "data = data.sort_values([\"Datetime\"])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N1s6ub4GN5hW",
        "outputId": "29a8819b-e1b7-40a5-a91d-7628e2c12853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date     Time Global_active_power Global_reactive_power Voltage  \\\n",
              "0 2007-01-01  0:00:00                2.58                 0.136  241.97   \n",
              "1 2007-01-01  0:01:00               2.552                   0.1  241.75   \n",
              "2 2007-01-01  0:02:00                2.55                   0.1  241.64   \n",
              "3 2007-01-01  0:03:00                2.55                   0.1  241.71   \n",
              "4 2007-01-01  0:04:00               2.554                   0.1  241.98   \n",
              "\n",
              "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \\\n",
              "0             10.6              0              0             0.0   \n",
              "1             10.4              0              0             0.0   \n",
              "2             10.4              0              0             0.0   \n",
              "3             10.4              0              0             0.0   \n",
              "4             10.4              0              0             0.0   \n",
              "\n",
              "             Datetime  \n",
              "0 2007-01-01 00:00:00  \n",
              "1 2007-01-01 00:01:00  \n",
              "2 2007-01-01 00:02:00  \n",
              "3 2007-01-01 00:03:00  \n",
              "4 2007-01-01 00:04:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8aefaecf-3068-4ef5-80b8-dc50e50b0941\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "      <th>Datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>2.58</td>\n",
              "      <td>0.136</td>\n",
              "      <td>241.97</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:01:00</td>\n",
              "      <td>2.552</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.75</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:02:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.64</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:03:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.71</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:04:00</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.1</td>\n",
              "      <td>241.98</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:04:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aefaecf-3068-4ef5-80b8-dc50e50b0941')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8aefaecf-3068-4ef5-80b8-dc50e50b0941 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8aefaecf-3068-4ef5-80b8-dc50e50b0941');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create list to store numeric columns\n",
        "num_cols = [\"Global_active_power\", \"Global_reactive_power\", \"Voltage\", \n",
        "            \"Global_intensity\",\"Sub_metering_2\", \"Sub_metering_3\"]\n",
        "\n",
        "# convert them into numeric datatype\n",
        "for col in num_cols:\n",
        "  # if there is any errors during the conversion, they will be set to NaN\n",
        "  data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
        "\n",
        "# first few rows\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UlhU7rVXOXlD",
        "outputId": "9d9988c0-b68c-4bb6-c637-d2d693c5ded9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date     Time  Global_active_power  Global_reactive_power  Voltage  \\\n",
              "0 2007-01-01  0:00:00                2.580                  0.136   241.97   \n",
              "1 2007-01-01  0:01:00                2.552                  0.100   241.75   \n",
              "2 2007-01-01  0:02:00                2.550                  0.100   241.64   \n",
              "3 2007-01-01  0:03:00                2.550                  0.100   241.71   \n",
              "4 2007-01-01  0:04:00                2.554                  0.100   241.98   \n",
              "\n",
              "   Global_intensity Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
              "0              10.6              0             0.0             0.0   \n",
              "1              10.4              0             0.0             0.0   \n",
              "2              10.4              0             0.0             0.0   \n",
              "3              10.4              0             0.0             0.0   \n",
              "4              10.4              0             0.0             0.0   \n",
              "\n",
              "             Datetime  \n",
              "0 2007-01-01 00:00:00  \n",
              "1 2007-01-01 00:01:00  \n",
              "2 2007-01-01 00:02:00  \n",
              "3 2007-01-01 00:03:00  \n",
              "4 2007-01-01 00:04:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4017f92e-48c9-4ddb-ad1d-5624dc0f841b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "      <th>Datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>2.580</td>\n",
              "      <td>0.136</td>\n",
              "      <td>241.97</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:01:00</td>\n",
              "      <td>2.552</td>\n",
              "      <td>0.100</td>\n",
              "      <td>241.75</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:02:00</td>\n",
              "      <td>2.550</td>\n",
              "      <td>0.100</td>\n",
              "      <td>241.64</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:03:00</td>\n",
              "      <td>2.550</td>\n",
              "      <td>0.100</td>\n",
              "      <td>241.71</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0:04:00</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.100</td>\n",
              "      <td>241.98</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-01-01 00:04:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4017f92e-48c9-4ddb-ad1d-5624dc0f841b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4017f92e-48c9-4ddb-ad1d-5624dc0f841b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4017f92e-48c9-4ddb-ad1d-5624dc0f841b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values in each numeric columns\n",
        "for col in num_cols:\n",
        "  missing = data[col].isna().sum()\n",
        "  print(f\"{col} missing values --> {missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFc38AwjvAq",
        "outputId": "7a9a029e-cc20-4c69-f66f-0516403761d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global_active_power missing values --> 3771\n",
            "Global_reactive_power missing values --> 3771\n",
            "Voltage missing values --> 3771\n",
            "Global_intensity missing values --> 3771\n",
            "Sub_metering_2 missing values --> 3771\n",
            "Sub_metering_3 missing values --> 3771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fill the missing values in those numeric columns with average\n",
        "for col in num_cols:\n",
        "  data[col].fillna(data[col].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "qbfF8LSNPhub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if there is any more missing values\n",
        "for col in num_cols:\n",
        "  missing = data[col].isna().sum()\n",
        "  print(f\"{col} missing values --> {missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2lqGDIfkmLE",
        "outputId": "7c35fbc1-9aa1-455e-f28a-2573697d2ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global_active_power missing values --> 0\n",
            "Global_reactive_power missing values --> 0\n",
            "Voltage missing values --> 0\n",
            "Global_intensity missing values --> 0\n",
            "Sub_metering_2 missing values --> 0\n",
            "Sub_metering_3 missing values --> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop no longer unnecessay columns from the dataframe:**"
      ],
      "metadata": {
        "id": "n6g31WzvlQua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the \"Date\", \"Time\", \"Global_reactive_power\", and \"Datetime\"\n",
        "df = data.drop([\"Date\", \"Time\", \"Global_reactive_power\", \"Datetime\"], axis=1)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UYtQpjFqk2of",
        "outputId": "bd5071d4-6c41-4ebd-c938-ab229dd43b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Global_active_power  Voltage  Global_intensity Sub_metering_1  \\\n",
              "0                2.580   241.97              10.6              0   \n",
              "1                2.552   241.75              10.4              0   \n",
              "2                2.550   241.64              10.4              0   \n",
              "3                2.550   241.71              10.4              0   \n",
              "4                2.554   241.98              10.4              0   \n",
              "\n",
              "   Sub_metering_2  Sub_metering_3  \n",
              "0             0.0             0.0  \n",
              "1             0.0             0.0  \n",
              "2             0.0             0.0  \n",
              "3             0.0             0.0  \n",
              "4             0.0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19c04438-6f35-49da-a36e-9b1d7d28d942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.580</td>\n",
              "      <td>241.97</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.552</td>\n",
              "      <td>241.75</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.550</td>\n",
              "      <td>241.64</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.550</td>\n",
              "      <td>241.71</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.554</td>\n",
              "      <td>241.98</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19c04438-6f35-49da-a36e-9b1d7d28d942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19c04438-6f35-49da-a36e-9b1d7d28d942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19c04438-6f35-49da-a36e-9b1d7d28d942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perfrom feature scaling to the dataframe:**"
      ],
      "metadata": {
        "id": "39kV8kcemLu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# rescale the feature values\n",
        "df = df.replace(\"?\", np.nan)\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "scaled_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv4KDVl7lvHR",
        "outputId": "d46fa764-09c0-462f-ff36-f8a7a293078e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23592747, 0.67445255, 0.22173913, 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.23328296, 0.66642336, 0.2173913 , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.23309407, 0.66240876, 0.2173913 , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.26445032, 0.56788321, 0.25217391, 0.        , 0.        ,\n",
              "        0.9       ],\n",
              "       [0.24348319, 0.56532847, 0.23478261, 0.        , 0.        ,\n",
              "        0.9       ],\n",
              "       [0.23290518, 0.57518248, 0.22173913, 0.        , 0.01282051,\n",
              "        0.85      ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare training and testing dataset:**"
      ],
      "metadata": {
        "id": "TcT-MybFquGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to store features and target variables\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# create a training dataset that has previous 60 minutes' power consumption\n",
        "# so that you can predict the value for the next minute\n",
        "for i in range(60, scaled_data.shape[0]):\n",
        "  X.append(scaled_data[i-60:i])\n",
        "  y.append(scaled_data[i, 0])"
      ],
      "metadata": {
        "id": "rzVg8alhmzhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the X and y into NumPy arrays in preparation for traning the model\n",
        "X, y = np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "7yTR7VIGrruh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into traning and testing sets with data before and after the index 217440\n",
        "X_train = X[:217440]\n",
        "y_train = y[:217440]\n",
        "\n",
        "X_test = X[217440:]\n",
        "y_test = y[217440:]"
      ],
      "metadata": {
        "id": "S4D9ooOVr6mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the RNN model**"
      ],
      "metadata": {
        "id": "Gh8-gEYEsjPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required libraries\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout"
      ],
      "metadata": {
        "id": "2_gcethlsYQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the RNN model architecture"
      ],
      "metadata": {
        "id": "MDTBPSA4tZt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a Sequential model\n",
        "regressor = Sequential()"
      ],
      "metadata": {
        "id": "aUxcqcwXuWcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a LSTM layer with 20units and \"relu\" activation function\n",
        "regressor.add(LSTM(units=20, activation=\"relu\", return_sequences=True, \n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "# add dropout layer with 50% to prevent overfitting\n",
        "regressor.add(Dropout(0.5))\n",
        "\n",
        "# add another LSTM layer with 40 units and \"relu\" activation function\n",
        "regressor.add(LSTM(units=40, activation=\"relu\", return_sequences=True))\n",
        "# add another dropout layer with a rate of 50% to prevent overfitting\n",
        "regressor.add(Dropout(0.5))\n",
        "\n",
        "# add another LSTM layer with 80 units and \"relu\" activation function\n",
        "# return_sequences = True, not required in final LSTM layer\n",
        "regressor.add(LSTM(units=80, activation=\"relu\"))\n",
        "# add another Dropout layer with a rate of 50% to prevent overfitting\n",
        "regressor.add(Dropout(0.5))\n",
        "\n",
        "# add a Dense output layer with 1 unit\n",
        "regressor.add(Dense(units=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8klnati4sysx",
        "outputId": "832d742b-a84a-4c28-fdd9-5b835608a0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the RNN model architecture\n",
        "regressor.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmxckBhXxHk9",
        "outputId": "99eea852-62e6-4189-a192-cb24640ffdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 60, 20)            2160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60, 20)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 60, 40)            9760      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 60, 40)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 80)                38720     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,721\n",
            "Trainable params: 50,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile the RNN model with Adam optimizer and MSE loss function**"
      ],
      "metadata": {
        "id": "fU_xUbHr0UZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.compile(\n",
        "    optimizer = \"Adam\",\n",
        "    loss = \"mean_squared_error\"\n",
        ")"
      ],
      "metadata": {
        "id": "xp7HnMmCzxm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit the RNN model to the training dataset**"
      ],
      "metadata": {
        "id": "xj9sUF350sGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=2,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7p9Y9ck0rkm",
        "outputId": "a8c9973c-f9fa-44f2-844f-5c907dc9d66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4169/6795 [=================>............] - ETA: 6:41 - loss: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a Prediction using the trained RNN model**"
      ],
      "metadata": {
        "id": "wmmDtFDZ4xO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tr-BFUw1AKO",
        "outputId": "c06f755c-bc30-4f8d-f1b0-28f0678cc7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1349/1349 [==============================] - 54s 40ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       ...,\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the real household power consumption and model's predictions for the last hour of data from test set**"
      ],
      "metadata": {
        "id": "FOkO56515v1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set the figure size\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# plot the last 60 values of the true power consumption\n",
        "plt.plot(y_test[-60:], color=\"black\", label=\"Real Power Consumption\")\n",
        "\n",
        "# plot the last 60 values of the predicted power consumption\n",
        "plt.plot(y_pred[-60:], color=\"red\", label=\"Predicted Power Consumption\")\n",
        "\n",
        "# set the title of the plot\n",
        "plt.title(\"Real v/s Predicted Power Consumption\")\n",
        "\n",
        "# set the x-axis and y-axis\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Power Consumption\")\n",
        "\n",
        "# add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "vg_iNUml59Ld",
        "outputId": "c073e3bd-8210-4f9f-86b7-729e0f44c52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAFNCAYAAADcnIQFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABhL0lEQVR4nO3dd3wU1frH8c9DCr0XRTqCINI7KohKsyEgKKAiKvq7KirqRewF9d5ruRYQReEqKlWkKqKgAoIIIShFQKRKEZPQpCchOb8/dhIXCKm7bBK+79drXtk5M3PmmZ0l7JNz5hxzziEiIiIiIiJpKxDqAERERERERHIzJU0iIiIiIiLpUNIkIiIiIiKSDiVNIiIiIiIi6VDSJCIiIiIikg4lTSIiIiIiIulQ0iQikguYWXsz2xHqOALFzPqb2SK/9UNmVvMMnHe+mQ0I9nkkcM7UZ0NEJCeUNImIZIGZbTWzo94XvT/NbIyZFcsFcZ2X1aTLiz3Bu5a9ZjbXzOoGIz7nXDHn3OYM4qluZs7MwoMRg5k9Z2aJ3vXuN7PFZtYmGOfKLjOraGb/M7NdZnbQzH41s+fNrGioYwuEtJLazHw2RERCTUmTiEjWXeecKwY0BpoAj4c2HACuBr7KxnGveNdSGYgFxpy8g/nkl/8vJnnXWx5YBEw1MzvTQaSVGJpZGeBHoDDQxjlXHOgIlALOP6MBiojICfLLf4IiImecc+5P4Gt8yRMAZtbaa8HYb2Yrzay937bbzWyd14Kw2cz+LzPnMbN3zey1k8pmmNnDfkVXA19624aY2U7vPOvN7MpMXMsRYDxQ36tjvpm9ZGY/AEeAmmZW12uN2uvVe6NfPGXNbKaZHTCzKE76ku+1INXyXhc2s/+a2e9m9peZLTKzwsD33u77vdagNt7+d3jv2z4z+9rMqvnV29FrjfnLzN4GMpUAOecSgY+Ac4GyXkvdTO/aNprZXV79hbyWxXLe+pNmdtzMSnjrL5jZm97rgmb2mpltM7MYMxvpXVdq90vv3vwJfJhGWA8DB4FbnHNbvTi3O+cedM6t8uq52MyWede7zMwu9nsv5nvx/ODd+zl+cRcys7Fmtsf7bC4zs3O8bVvNrINfPc+Z2VjvdUrr3+1mtt27B/8wsxZmtsqr622/Y/t753/bi/HXlM+fmb0EtAXe9u7v22l8Nkqa2cdmFud9Pp4yL2H36l7kvcf7zGyLmV2VmfstIpJTSppERLLJzCoDVwEbvfVKwCzgRaAM8E9gipmV9w6JBa4FSgC3A2+YWdNMnGoCcJOZr0XEzEoDnYCJ3noE0A6Ya2Z1gIFAC6+lojOwNRPXUgy4GfjZr/hW4G6gOBAHzMWXWFUAegPvmFk9b98RwDGgInCHt5zOa0Az4GJ879OjQLJ3DQClvC5bP5rZ9cATQA98rUMLvfcDLyGYCjwFlAM2AZdkdK3esQWB/sB259xufO/lDuA8oCfwLzO7wjl3DFgGXOYdehnwu995LgMWeK//A1yAL4muBVQCnvE77bne9VbD976erAMw1TmXfJqYy+D7fA0DygKvA7PMrKzfbn3xfbYqAJH4PoMAtwElgSresf8AjqZ1ntNoBdQGbgLeBJ704r0IuNHMLjtp30347smz+FrzyjjnnsR3/wZ693dgGucZ7sVZE99728+7Hv+613t1vwL8L+XfhYhIMClpEhHJuulmdhDYji8RetYrvwX40jn3pXMu2Tk3F4jG1wqEc26Wc26T81kAzMH3l/eMLASc3749gR+dc3946+2Alc65g0ASUBCoZ2YRzrmtzrlN6dT9TzPbjy/xK4YvkUgxxjm3xjl3HOgCbHXOfeicO+6c+xmYAvQyszDgBuAZ59xh59wv+FpxTuG1GtwBPOic2+mcS3LOLXbOxZ8mvn8A/3bOrfPi+BfQ2GttuhpY45z7zGs5ehP4M51rBd8X/P347l0zoLuZVcGXBA1xzh1zzq0ARuP7wg6+pOgy83Wpa4gvabnMzAoBLYDvvS/udwMPOef2evfiX/iSyxTJwLPOuXjnXFoJS1lgVzqxXwNscM594t2DCcCvwHV++3zonPvNq/9T/m4FTfTqr+W958udcwcyeK/8veC9N3OAw8AE51ysc24nvs9nE799Y4E3nXOJzrlJ+JKcazI6gfc56g087pw76LW2/Rdf8p7id+fcKOdcEr7PWEXgnCxch4hItihpEhHJum5eK057oC6+v3qDrwWhl9dlab/35fxSfF/sMLOrzGyJ1wVsP74v/eVOrvxkzjmHryWkj1fUFxjnt0tq1zzn3EZgEPAcEGtmE83svHSqf805V8o5d65zrutJCdZ2v9fVgFYnXdvN+FpPygPhJ+3/+2nOVw4ohK8lIjOqAW/5nXMvvi54lfC1CqWe03uftqdViZ9Pveut4Jy7wjm33KsnJdHxj7+S93oBvnvdFFiNr8XtMqA1sNE5twffe1AEWO4X61deeYo4r+XqdPbgfVZO4zxOfV/944QTk8Yj+BJhgE/wdSWdaGZ/mNkrXgtlZsX4vT6axrr/YCg7vXvhH2N6n8EU5YAITrzG016f16WUk84tIhIUSppERLLJay0ag6+7Gfi+sH/ifSlPWYo65/7jdQeb4u17jnOuFL5EJ7NdiyYAPb0WllZeXSlSkyYvrvHOuUvxJRwOeDm7l+j3ejuw4KRrK+acuwdf173j+Lp+pah6mjp34+vGl9bABi6Nsu3A/5103sLOucX4WmVSz+m19lRJo46M/AGUMbPiJ8W/03u9GKgDdMf3Hqz1tl/N313zduNLHi7yi7OkN+hEetfn7xt8LV+n+7/5D3z31J9/nKfltfo875yrh69b5LX83ZJ2GF/Cl+LcjOrLQKWTusxVxRc7pP8e7MbXIuZ/jZm6PhGRYFPSJCKSM28CHc2sETAWuM7MOptZmPfwfXvv2adIfN3m4oDj3gPsnTJ7Eq873G583ca+ds7tBzCzGkBB59w6b72OmV3hJWnH8H2RT/MZmSz6ArjAzG41swhvaWFmF3pdpaYCz5lZEe85p9tOcx3JwAfA6+YbfCHMzNp48cZ5sfrP2TMSeNzMLvKur6SZ9fK2zQIuMrMeXte5B8jGF37n3HZ8idG/vXvWELgT3/1MadFYDtzH30nSYnxdBxf4XdcofM+pVfBirWRmnbMQyuv4nnf7yEuOU+p43YvpS3z3oK+ZhZvZTUA9fPcmXWZ2uZk18LrAHcCXnKR8LlYAvb172hxf98+cqAA84NXXC7iQv5P6GE68v6m8z9GnwEtmVtx7Dx7Guw8iIqGkpElEJAecc3HAx/ie59kOpAxcEIevlWQwUMDr+vUAvi+F+/B1sZuZxdONx/fw/Xi/smvwa2XCl5j9B1+C9Se+L7A5HhLdi78TvmdO/vDqftk7H/gGnyjmlY8h7dHhUvwTXze3Zfi6272M7z06ArwE/OB1cWvtnJvmbZ9oZgeAX/ANvoE3gEMv73r34Buo4IdsXmIfoLp3bdPwPXv0jd/2Bfi6jkX5rRfn7xH/AIbgezZsiRfrN/haqDLFObcXXytQIrDUe27uW+Av/u4GeC3wCL7rfRS41nsfMnIu8Bm+hGmdF/8n3ran8bX87QOe58TPV3YsxXcvduO7nz292AHewtdius/MhqVx7P34Wr424xsSfjy+JFtEJKTsxG7HIiKSl5jZl8DbzrkvM9xZJMjMrD8wwOseKiKSb6ilSUQkb5sPzAt1ECIiIvnZKTOSi4hI3uGceyXUMYiIiOR36p4nIiIiIiKSjqB2zzOzLma23sw2mtljaWx/2MzWmtkqM/vWb7Sgy81shd9yzMy6edvGmNkWv22Ng3kNIiIiIiJydgtaS5M3rOlvQEdgB75Rkvp481uk7HM5sNQ5d8TM7gHaO+duOqmeMvhGI6rs7TcG+MI591lQAhcREREREfETzGeaWuIbInUzgJlNxDcUb2rS5Jzzf3h5CXBLGvX0BGb7zfydZeXKlXPVq1fP7uEiIiIiIpLPLV++fLdzrnxa24KZNFXCN0dJih34ZrE/nTuB2WmU98Y34Z+/l8zsGXzzVzzmnItPL5Dq1asTHR2dccQiIiIiInJWMrPfT7ctVww5bma3AM2BV08qrwg0AL72K34cqAu0AMrgm0wwrTrvNrNoM4uOi4sLStwiIiIiIpL/BTNp2glU8Vuv7JWdwMw6AE8CXdNoMboRmOacS0wpcM7tcj7x+Gacb5nWyZ1z7zvnmjvnmpcvn2Yrm4iIiIiISIaCmTQtA2qbWQ0zi8TXzW6m/w5m1gR4D1/CFJtGHX2ACScdU9H7aUA34JfAhy4iIiIiIuITtGeanHPHzWwgvq51YcAHzrk1ZjYUiHbOzcTXHa8YMNmXA7HNOdcVwMyq42upWnBS1ePMrDxgwArgH9mJLzExkR07dnDs2LHsHC6SqxUqVIjKlSsTERER6lBERERE8ryzYnLb5s2bu5MHgtiyZQvFixenbNmyeAmbSL7gnGPPnj0cPHiQGjVqhDocERERkTzBzJY755qntS1XDAQRCseOHVPCJPmSmVG2bFm1ooqIiIgEyFmbNAFKmCTf0mdbREREJHDO6qQp1MLCwmjcuDH169fnuuuuY//+/dmqZ8yYMQwcODDN8vLly9O4cWPq1avHqFGjchhx9kRFRdGuXTvq1KlDkyZNGDBgAEeOZHuu4jNm+vTprF2bOhczzzzzDN98800IIxIRERGRUFDSFEKFCxdmxYoV/PLLL5QpU4YRI0YE/Bw33XQTK1asYP78+TzxxBPExMQE/Bz+jh8/fsJ6TEwMvXr14uWXX2b9+vX8/PPPdOnShYMHDwY1jkA4OWkaOnQoHTp0CGFEIiIiIhIKSppyiTZt2rBzp28aq02bNtGlSxeaNWtG27Zt+fXXXwH4/PPPadWqFU2aNKFDhw5ZSoAqVKjA+eefz++//863335LkyZNaNCgAXfccQfx8fEsW7aMHj16ADBjxgwKFy5MQkICx44do2bNmunG1b9/f/7xj3/QqlUrHn300RPOO2LECG677TbatGmTWtazZ0/OOecc9u7dS7du3WjYsCGtW7dm1apVADz33HPccccdtG/fnpo1azJs2DAADh8+zDXXXEOjRo2oX78+kyZNAqB69ers3r0bgOjoaNq3b59az2233Ubbtm2pVq0aU6dO5dFHH6VBgwZ06dKFxMTE1ONTylu2bMnGjRtZvHgxM2fOZPDgwTRu3JhNmzbRv39/PvvsM4A038OUup599lmaNm1KgwYNUt8jERERyV1iY2P58MMP+fjjj5k4cSJTp07liy++4Ouvv2bevHn88MMPLFu2jJUrV7Ju3To2bdrEnj17Qh22hEjQhhyXzEtKSuLbb7/lzjvvBODuu+9m5MiR1K5dm6VLl3Lvvffy3Xffcemll7JkyRLMjNGjR/PKK6/w3//+N1Pn2Lx5M5s3b6Zy5cq0atWKb7/9lgsuuIB+/frx7rvvMnDgQFasWAHAwoULqV+/PsuWLeP48eO0atUq3bgAduzYweLFiwkLCzvhvL/88gu33XZbmjE9++yzNGnShOnTp/Pdd9/Rr1+/1Bh+/fVX5s2bx8GDB6lTpw733HMPX331Feeddx6zZs0C4K+//srwujdt2sS8efNYu3Ytbdq0YcqUKbzyyit0796dWbNm0a1bNwBKlizJ6tWr+fjjjxk0aBBffPEFXbt25dprr6Vnz54n1Hns2DH69+9/yns4aNAgAMqVK8dPP/3EO++8w2uvvcbo0aMzjFNERETOrNdff52XX345y8dVrVqVFi1apC7NmjWjZMmSQYhQchMlTcCgQYNSv6wHSuPGjXnzzTfT3efo0aM0btyYnTt3cuGFF9KxY0cOHTrE4sWL6dWrV+p+Ka0YO3bs4KabbmLXrl0kJCRkajjpSZMmsWjRIgoWLMh7771HXFwcNWrU4IILLgDgtttuY8SIEQwaNIjzzz+fdevWERUVxcMPP8z3339PUlISbdu2TTcugF69ep2SMGVk0aJFTJkyBYArrriCPXv2cODAAQCuueYaChYsSMGCBalQoQIxMTE0aNCARx55hCFDhnDttdfStm3bDM9x1VVXERERQYMGDUhKSqJLly4ANGjQgK1bt6bu16dPn9SfDz30ULp1rl+//rTvIZDaYtesWTOmTp2a+TdEREREzpidO3dSuXJlFixYQEJCQuqSmJh4wrr/EhMTQ3R0NMuWLUv9DgNQp06dExKpxo0bU7hw4RBenQSakqYQSnmm6ciRI3Tu3JkRI0bQv39/SpUqlWYSd//99/Pwww/TtWtX5s+fz3PPPZfhOW666Sbefvvt1PWVK1eedt927doxe/ZsIiIi6NChA/379ycpKYlXX32V5OTk08YFULRo0TTLL7roIpYvX87111+fYaz+ChYsmPo6LCyM48ePc8EFF/DTTz/x5Zdf8tRTT3HllVfyzDPPEB4eTnJyMsApw2yn1FOgQAEiIiJSR5UrUKDACc9f+Y82l9OR51LOmRK3iIiI5D6xsbGcd955qY8hZNWePXtSE6hly5bx7bffMnbsWADCw8OpX78+LVq0oFGjRjRu3JiGDRtSvHjxQF5CljjnOHLkCEWKFNEou9mgpAkybBEKtiJFijBs2DC6devGvffeS40aNZg8eTK9evXCOceqVato1KgRf/31F5UqVQLgo48+yta56tSpw9atW9m4cSO1atXik08+4bLLLgOgbdu29OvXj379+lG+fHn27NlDTEwM9evXx8xOG1d6Bg4cSMuWLbnmmmtSu/lNnTqVSy65hLZt2zJu3Diefvpp5s+fT7ly5ShRosRp6/rjjz8oU6YMt9xyC6VKlUrt9la9enWWL1/OVVdddcJffbJi0qRJPPbYY0yaNCn1+avixYunOWBFeu+hiIiI5A2xsbFUqVIl28eXLVuWzp0707lz59SynTt3piZRUVFRfPbZZyeMXlyzZs3UJKpRo0Y0atSIatWqBSyJSUpKYvv27WzatImNGzee8HPTpk0cPnyYYsWKUbVqVapUqZLmz8qVK1OoUKGAxJOfKGnKJZo0aULDhg2ZMGEC48aN45577uHFF18kMTGR3r1706hRI5577jl69epF6dKlueKKK9iyZUuWz1OoUCE+/PBDevXqxfHjx2nRogX/+Mc/AGjVqhUxMTG0a9cOgIYNG/Lnn3+m/kM+XVzpOeecc5g4cSL//Oc/iY2NpUCBArRr144uXbqkDvjQsGFDihQpkmEiuHr1agYPHpzaavTuu+8Cvmej7rzzTp5++unUQSCyat++fTRs2JCCBQsyYcIEAHr37s1dd93FsGHDUgeAyOg9FBERkbwhJiaGZs2aBbTOSpUqUalSpdRnpp1z7Nixg5UrV56wTJ8+Hecc4HuuOiWBqlOnDuHhmf96fvToUTZv3pyaHG3ZsiV1oCuAyMhIatasyfnnn8/ll1/Oueeey59//sn27dvZtm0bK1asSHNgsfLly1O1alXq1KnDyJEjQ9pClltYyg3Lz5o3b+6io6NPKFu3bh0XXnhhiCKS3KR69epER0dTrly5UIcSUPqMi4iIpC05OZmCBQsyePBg/vWvf53x8x8+fJjVq1efkEitWrWKQ4cOZbmu4sWLc/7551OrVi3OP//8E15XqlQpw2fOjx07xs6dO9m2bVtqMrV9+3a2bNnC3LlzGTFiBPfee292LzVPMbPlzrnmaW1TS5OIiIiInFX27dvH8ePHOeecc0Jy/qJFi9K6dWtat26dWpacnExcXFzqc9qZERkZSZkyZXLUva9QoUKpyZY/5xxNmzZl9OjRZ03SlB4lTXLW8x9FT0RERPK/2NhYwDePZW5RoECBkCVxaTEzBgwYwMCBA/npp59o2rRpqEMKKU1uKyIiIiJnldyYNOVGN998M4UKFdKckyhpEhEREZGzTMrgB7mpZSc3KlWqFL169WLcuHEcOXIk1OGElJImERERETmrqKUp8wYMGMCBAwdOGEn4bKSkSURERETOKinToJQtWzbUoeR6bdu2pXbt2ifMN3U2UtIUQmFhYTRu3Jj69evTq1evHDV79u/fP/UvAAMGDGDt2rWn3Xf+/PksXrw4y+eoXr06u3fvTrO8QYMGNGzYkE6dOvHnn39mue6cSkxM5LHHHqN27do0bdqUNm3aMHv27DMeR1bt37+fd955J3X9jz/+oGfPniGMSEREJP+LiYmhXLlyGQ7HLX8PCLFo0SJ+/fXXUIcTMkqaQqhw4cKsWLGCX375hcjISEaOHHnC9uPHj2er3tGjR1OvXr3Tbs9u0pSeefPmsWrVKpo3bx70+Q6cc6cMx/n000+za9cufvnlF3766SemT5/OwYMHgxpHIJycNJ133nlnffO3iIhIsMXGxqprXhb069eP8PBw/ve//4U6lJBR0pRLtG3blo0bNzJ//nzatm1L165dqVevHklJSQwePJgWLVrQsGFD3nvvPcCXOAwcOJA6derQoUOH1L65AO3btydlMt+vvvqKpk2b0qhRI6688kq2bt3KyJEjeeONN2jcuDELFy4kLi6OG264gRYtWtCiRQt++OEHAPbs2UOnTp246KKLGDBgAJmZCLldu3Zs3LiRY8eOcfvtt9OgQQOaNGnCvHnzALjmmmtYtWoVAE2aNGHo0KEAPPPMM6nNvq+++mrq9T777LOAb1jwOnXq0K9fP+rXr8/27dtTz3nkyBFGjRrF8OHDKViwIOB7sPPGG28EYMKECTRo0ID69eszZMiQ1OOKFSvGk08+SaNGjWjdunXqQ6GTJ0+mfv36NGrUiHbt2gEwZswYBg4cmHrstddey/z581PrGTx4MBdddBEdOnQgKiqK9u3bU7NmTWbOnJl6/PXXX0/79u2pXbs2zz//PACPPfYYmzZtonHjxgwePJitW7dSv359gNO+h2PGjKFHjx506dKF2rVr8+ijj2Z4X0RERORvSpqy5txzz+W6667jo48+IiEhIdThhISSplzg+PHjzJ49mwYNGgDw008/8dZbb/Hbb7/xv//9j5IlS7Js2TKWLVvGqFGj2LJlC9OmTWP9+vWsXbuWjz/+OM2Wo7i4OO666y6mTJnCypUrmTx5MtWrV+cf//gHDz30ECtWrKBt27Y8+OCDPPTQQyxbtowpU6YwYMAAAJ5//nkuvfRS1qxZQ/fu3dm2bVuG1/LFF1/QoEEDRowYgZmxevVqJkyYwG233caxY8do27YtCxcu5K+//iI8PDw1QVu4cCHt2rVjzpw5bNiwgaioKFasWMHy5cv5/vvvAdiwYQP33nsva9asoVq1aqnn3LhxI1WrVqVEiRKnxPPHH38wZMgQvvvuO1asWMGyZcuYPn064JuNu3Xr1qxcuZJ27dqlJm1Dhw7l66+/ZuXKlalJT3oOHz7MFVdcwZo1ayhevDhPPfUUc+fOZdq0aTzzzDOp+0VFRTFlyhRWrVrF5MmTiY6O5j//+Q/nn38+K1as4NVXXz2h3tO9hwArVqxg0qRJrF69mkmTJp2QRIqIiEj6YmJiNHJeFg0YMIC4uDg+//zzUIcSEprcFmDQIFixIrB1Nm4Mb76Z7i5Hjx6lcePGgK+l6c4772Tx4sW0bNmSGjVqADBnzhxWrVqV2mXrr7/+YsOGDXz//ff06dOHsLAwzjvvPK644opT6l+yZAnt2rVLratMmTJpxvHNN9+c8AzUgQMHOHToEN9//z1Tp04FfC1EpUuXPu21XH755YSFhdGwYUNefPFFbr/9du6//34A6tatS7Vq1fjtt99o27Ytw4YNo0aNGlxzzTXMnTuXI0eOsGXLFurUqcOoUaOYM2cOTZo0AeDQoUNs2LCBqlWrUq1atRNmzs6MZcuW0b59e8qXLw/45hv4/vvv6datG5GRkVx77bUANGvWjLlz5wJwySWX0L9/f2688UZ69OiR4TkiIyPp0qULAA0aNKBgwYJERETQoEGDEybO7dixY+oDpz169GDRokV069bttPUuWrQozfcQ4Morr6RkyZIA1KtXj99//50qVapk4Z0RERE5e6mlKes6d+5M5cqVGT16NDfccEOowznjlDSFUMozTScrWrRo6mvnHMOHD6dz584n7PPll18GLI7k5GSWLFlCoUKFsl3HvHnzKFeuXIb7tWjRgujoaGrWrEnHjh3ZvXs3o0aNolmzZoDveh9//HH+7//+74Tjtm7desL74q9WrVps27aNAwcOpNnadDoRERGYGeAblCPlGbKRI0eydOlSZs2aRbNmzVi+fDnh4eEnPEeV0uJzcj0FChRI7SJYoECBE55LS9nndOtZkXKOk2MXERGR9B09epSDBw+qpSmLwsLCuOOOO3jhhRfYtm0bVatWDXVIZ5S654GvRWj+/MAuGbQyZVbnzp159913SUxMBOC3337j8OHDtGvXjkmTJpGUlMSuXbtSn3fx17p1a77//nu2bNkCwN69ewEoXrz4CYMkdOrUieHDh6eupyRy7dq1Y/z48QDMnj2bffv2ZTrutm3bMm7cuNSYt23bRp06dYiMjKRKlSpMnjyZNm3a0LZtW1577bXUZ4c6d+7MBx98wKFDhwDYuXPnCc9rpaVIkSLceeedPPjgg6n9bOPi4pg8eTItW7ZkwYIF7N69m6SkJCZMmMBll12Wbn2bNm2iVatWDB06lPLly7N9+3aqV6/OihUrSE5OZvv27URFRWX6vUgxd+5c9u7dy9GjR5k+fTqXXHLJKffC3+neQxEREck+zdGUfbfffjsAH374YYgjOfOUNOVyAwYMoF69ejRt2pT69evzf//3fxw/fpzu3btTu3Zt6tWrR79+/WjTps0px5YvX57333+fHj160KhRI2666SYArrvuOqZNm5Y6EMSwYcOIjo6mYcOG1KtXL3UUv2effZbvv/+eiy66iKlTp2bpLwr33nsvycnJNGjQgJtuuokxY8akto60bduWChUqULhwYdq2bcuOHTto27Yt4Evg+vbtS5s2bWjQoAE9e/bM1Ch4L774IuXLl6devXrUr1+fa6+9lhIlSlCxYkX+85//cPnll9OoUSOaNWvG9ddfn25dgwcPTh044uKLL6ZRo0Zccskl1KhRg3r16vHAAw/QtGnTTL8XKVq2bMkNN9xAw4YNueGGG2jevDlly5blkksuoX79+gwePDjT76GIiIhkj5Km7KtevTodO3bkgw8+ICkpKdThnFGWmRHR8rrmzZu7lNHkUqxbt44LL7wwRBHJ2WbMmDFER0fz9ttvn7Fz6jMuIiJyqlmzZnHttdeydOlSWrZsGepw8pzJkydz44038tVXX53y+EheZ2bLnXPN09qmliYREREROWukTDGilqbs6dq1K+XKlUsddfhsEdSkycy6mNl6M9toZo+lsf1hM1trZqvM7Fszq+a3LcnMVnjLTL/yGma21KtzkplFBvMaRAKhf//+Z7SVSURERNKm7nk5U7BgQfr168eMGTMyfO48Pwla0mRmYcAI4CqgHtDHzOqdtNvPQHPnXEPgM+AVv21HnXONvaWrX/nLwBvOuVrAPuDOYF2DiIiIiOQvMTExFCtWjCJFioQ6lDxrwIABHD9+nI8//jjUoZwxwWxpaglsdM5tds4lABOBE57Ad87Nc84d8VaXAJXTq9B8YzRfgS/BAvgI6JbdAM+G57nk7KTPtoiISNo0R1POXXjhhVxyySWMHj36rPnOEcykqRKw3W99h1d2OncCs/3WC5lZtJktMbNuXllZYL9zLmVSmozqPK1ChQqxZ8+es+ZGy9nDOceePXtyNO+WiIhIfqWkKTAGDBjA+vXr+eGHH0IdyhmRKya3NbNbgOaA/wQ61ZxzO82sJvCdma0G/spCnXcDdwNpDpVduXJlduzYQVxcXI5iF8mNChUqROXK6TbcioiInJViYmKoWbNmqMPI83r16sUDDzzA6NGjufTSS0MdTtAFM2naCVTxW6/slZ3AzDoATwKXOefiU8qdczu9n5vNbD7QBJgClDKzcK+1Kc06vePeB94H35DjJ2+PiIigRo0a2bsyEREREcmTYmNjad26dajDyPOKFi1K3759+fjjj3nrrbcoWbJkqEMKqmB2z1sG1PZGu4sEegMz/XcwsybAe0BX51ysX3lpMyvovS4HXAKsdb6+dPOAnt6utwEzgngNIiIiIpJPJCcnExcXp+55ATJgwACOHj3KhAkTQh1K0AUtafJaggYCXwPrgE+dc2vMbKiZpYyG9ypQDJh80tDiFwLRZrYSX5L0H+fcWm/bEOBhM9uI7xmn/wXrGkREREQk/9izZw/Jycmcc845oQ4lX2jWrBmNGjVi9OjRoQ4l6IL6TJNz7kvgy5PKnvF73eE0xy0GGpxm22Z8I/OJiIiIiGSa5mgKLDNjwIAB3H///fz88880adIk1CEFTVAntxURERERyS1Skia1NAXOzTffTKFChfJ9a5OSJhERERE5K8TExABqaQqk0qVL07NnT8aNG8eRI0cyPiCPUtIkIiIiImcFdc8LjgEDBvDXX38xZcqUUIcSNEqaREREROSsEBsbS1hYGGXKlAl1KPlKu3btqFWrVr7uoqekSURERETOCjExMZQvX54CBfQVOJBSBoT4/vvviY6ODnU4QaFPjIiIiIicFWJjY9U1L0juuusuKleuzI033si+fftCHU7AKWkSERERkbNCbGysRs4LkjJlyjB58mR27NhBv379SE5ODnVIAaWkSURERETOCjExMWppCqLWrVvz+uuv88UXX/Dvf/871OEElJImERERETkrqHte8N1333307duXp59+mrlz54Y6nIBR0iQiIiIi+d7hw4c5fPiwuucFmZnx/vvvU69ePfr27cv27dtDHVJAKGkSERERkXxPczSdOUWLFmXKlCnEx8fTq1cv4uPjQx1SjilpEhEREZF8LyVpUkvTmVGnTh0+/PBDli5dyiOPPBLqcHJMSZOIiIiI5HsxMTGAWprOpBtuuIF//vOfjBgxgnHjxoU6nBxR0iQiIiIi+Z6654XGv//9b9q1a8fdd9/NL7/8Eupwsk1Jk4iIiIjke0qaQiM8PJyJEydSokQJevTowYEDB0IdUrYoaRIRERGRfC8mJoYSJUpQqFChUIdy1qlYsSKffvopmzdv5vbbb8c5F+qQskxJk4iIiIjke5qjKbTatm3LK6+8wtSpU/nvf/8b6nCyTEmTiIiIiOR7sbGxGjkvxB566CF69uzJY489xoIFC0IdTpYoaRIRERGRfC8mJkYtTSFmZnzwwQfUqlWLm266iT/++CPUIWWakiYRERERyffUPS93KF68OFOnTuXQoUPcdNNNJCYmhjqkTFHSJCIiIiL5WlJSErt371b3vFyiXr16jBo1ikWLFjFr1qxQh5Mp4aEOQEREREQkmHbv3o1zTi1NuUifPn2oU6cOTZs2DXUomaKWJhERERHJ1zRHU+6UVxImUNIkIiIiIvlcTEwMgLrnSbYpaRIRERGRfE0tTZJTSppEREREJF9LSZrU0iTZpaRJRERERPK1mJgYwsPDKVWqVKhDkTxKSZOIiIiI5GspczSZWahDkTwqqEmTmXUxs/VmttHMHktj+8NmttbMVpnZt2ZWzStvbGY/mtkab9tNfseMMbMtZrbCWxoH8xpEREREJG+LjY1V1zzJkaAlTWYWBowArgLqAX3MrN5Ju/0MNHfONQQ+A17xyo8A/ZxzFwFdgDfNrJTfcYOdc429ZUWwrkFERERE8r6YmBgNAiE5EsyWppbARufcZudcAjARuN5/B+fcPOfcEW91CVDZK//NObfBe/0HEAuUD2KsIiIiIpJPpXTPE8muYCZNlYDtfus7vLLTuROYfXKhmbUEIoFNfsUved323jCzgoEIVkRERETyH+ecuudJjuWKgSDM7BagOfDqSeUVgU+A251zyV7x40BdoAVQBhhymjrvNrNoM4uOi4sLWuwiIiIiknsdOnSIo0ePqqVJciSYSdNOoIrfemWv7ARm1gF4EujqnIv3Ky8BzAKedM4tSSl3zu1yPvHAh/i6AZ7COfe+c665c655+fLq2SciIiJyNtLEthIIwUyalgG1zayGmUUCvYGZ/juYWRPgPXwJU6xfeSQwDfjYOffZScdU9H4a0A34JYjXICIiIiJ5mCa2lUAID1bFzrnjZjYQ+BoIAz5wzq0xs6FAtHNuJr7ueMWAyd64+ducc12BG4F2QFkz6+9V2d8bKW+cmZUHDFgB/CNY1yAiIiIieVtMTAyglibJmaAlTQDOuS+BL08qe8bvdYfTHDcWGHuabVcEMkYRERERyb/UPU8CIVcMBCEiIiIiEgxKmiQQlDSJiIiISL4VExNDqVKliIyMDHUokocpaRIRERGRfEtzNEkgKGkSERERkXwrJiZGXfMkx5Q0iYiIiEi+FRsbq6RJckxJk4iIiIjkW+qeJ4GgpElERERE8qXExET27NmjlibJMSVNIiIiIpIv7d69G9Bw45JzmZrc1szCgHP893fObQtWUCIiIiIiOZUyR5O650lOZZg0mdn9wLNADJDsFTugYRDjEhERERHJkZiYGEAtTZJzmWlpehCo45zbE+xgREREREQCJaWlSUmT5FRmnmnaDvwV7EBERERERAJJ3fMkUDLT0rQZmG9ms4D4lELn3OtBi0pEREREJIdiYmKIjIykRIkSoQ5F8rjMJE3bvCXSW0REREREcr2UOZrMLNShSB6XYdLknHsewMyKeeuHgh2UiIiIiEhOxcbG6nkmCYgMn2kys/pm9jOwBlhjZsvN7KLghyYiIiIikn0xMTFKmiQgMjMQxPvAw865as65asAjwKjghiUiIiIikjMp3fNEciozSVNR59y8lBXn3HygaNAiEhERERHJIeecuudJwGRq9Dwzexr4xFu/Bd+IeiIiIiIiudKBAweIj49X0iQBkZmWpjuA8sBUbynvlYmIiIiI5Eqao0kCKTOj5+0DHjgDsYiIiIiIBERMTAyAWpokIE6bNJnZm865QWb2OeBO3u6c6xrUyEREREREsimlpUlJkwRCei1NKc8wvXYmAhERERERCRR1z5NAOm3S5Jxb7r1s7Jx7y3+bmT0ILAhmYCIiIiIi2ZXSPa9cuXIhjkTyg8wMBHFbGmX9AxyHiIiIiEjAxMbGUqZMGSIiIkIdiuQD6T3T1AfoC9Qws5l+m0oAe4MdmIiIiIhIdmliWwmk9J5pWgzsAsoB//UrPwisCmZQIiIiIiI5ERMTo0EgJGBO2z3POfe7c26+c64NsB4oia+V6Q/n3PEzFaCIiIiISFappUkCKcNnmszsTiAK6AH0BJaYWaYmtzWzLma23sw2mtljaWx/2MzWmtkqM/vWzKr5bbvNzDZ4y21+5c3MbLVX5zAzs8zEIiIiIiJnj9jYWLU0ScBkZiCIR4Emzrn+zrnbgGbAkIwOMrMwYARwFVAP6GNm9U7a7WeguXOuIfAZ8Ip3bBngWaAV0BJ41sxKe8e8C9wF1PaWLpm4BhERERE5SyQkJLBv3z4lTRIwmUma9uB7jinFQa8sIy2Bjc65zc65BGAicL3/Ds65ec65I97qEqCy97ozMNc5t9c5tw+YC3Qxs4pACefcEuecAz4GumUiFhERERE5S8TFxQGao0kCJ72BIFJsBJaa2QzA4Ut8VpnZwwDOuddPc1wlYLvf+g58LUencycwO51jK3nLjjTKRURERESAvye2VUuTBEpmkqZN3pJihvezeKCCMLNbgObAZQGs827gboCqVasGqloRERERyeVSJrZV0iSBkmHS5Jx7Ppt17wSq+K1X9spOYGYdgCeBy5xz8X7Htj/p2PleeeWTyk+p04v7feB9gObNm7vsXICIiIiI5D0pLU3qnieBkpnR85qb2TQz+8kb5W6VmWVmnqZlQG0zq2FmkUBvwH+SXMysCfAe0NU5F+u36Wugk5mV9gaA6AR87ZzbBRwws9beqHn9+LvlS0RERERELU0ScJnpnjcOGAysBpIzW7Fz7riZDcSXAIUBHzjn1pjZUCDaOTcTeBUoBkz2Rg7f5pzr6pzba2Yv4Eu8AIY65/Z6r+8FxgCF8T0DNRsREREREU9sbCyFChWiWLFioQ5F8onMJE1xXoKTZc65L4EvTyp7xu91h3SO/QD4II3yaKB+duIRERERkfwvZWJbTecpgZKZpOlZMxsNfAukPHOEc25q0KISEREREcmmmJgYdc2TgMpM0nQ7UBeI4O/ueQ5Q0iQiIiIiuU5sbCyVKmlWGgmczCRNLZxzdYIeiYiIiIhIAMTGxtKkSZNQhyH5SIaj5wGLzaxe0CMREREREckh5xyxsbHqnicBlZmWptbACjPbgu+ZJgOcc65hUCMTEREREcmi/fv3k5iYqDmaJKAykzR1CXoUIiIiIiIBkDKxrVqaJJAykzS5oEchIiIiIhIAmthWgiEzSdMsfImTAYWAGsB64KIgxiUiIiIikmUpLU3qnieBlGHS5Jxr4L9uZk2Be4MWkYiIiIhINql7ngRDZkbPO4Fz7iegVRBiERERERHJkZiYGMyMsmXLhjoUyUcybGkys4f9VgsAzYA/ghaRiIiIiEg2xcbGUq5cOcLDM/MUikjmZObTVNzv9XHgC2BKcMIREREREck+zdEkwZCZZ5qeT3ltZgWAYs65Y0GNSkREREQkG2JiYpQ0ScBl+EyTmY03sxJmVhT4BVhrZoODH5qIiIiISNbExsZq5DwJuMwMBFHPOXcA6AbMxjfk+K3BDEpEREREJDvU0iTBkJmkKcLMIvAlTTOdc4lowlsRERERyWWOHTvGgQMH1NIkAZeZpOk9YCtQFPjezKoBB4IZlIiIiIhIVsXFxQGao0kCLzMDQQwDhvkV/W5mlwcvJBERERGRrIuJiQGUNEngZWaepoLADUD1k/YfGqSYRERERESyLDY2FkDd8yTgMjNP0wzgL2A5EB/ccEREREREsiclaVJLkwRaZpKmys65LkGPREREREQkB9Q9T4IlMwNBLDazBkGPREREREQkB2JjYylatChFixYNdSiSz2SmpelSoL+ZbcHXPc8A55xrGNTIRERERESyIDY2Vq1MEhSZSZquCnoUIiIiIiI5pIltJVgy7J7nnPsdKAVc5y2lvDIRERERkVwjNjZWI+dJUGSYNJnZg8A4oIK3jDWz+4MdmIiIiIhIVqh7ngRLZrrn3Qm0cs4dBjCzl4EfgeHBDExEREREJLOSk5OVNEnQZGb0PAOS/NaTvDIRERERkVxh3759JCUlqXueBEVmkqYPgaVm9pyZPQcsAf6XmcrNrIuZrTezjWb2WBrb25nZT2Z23Mx6+pVfbmYr/JZjZtbN2zbGzLb4bWucmVhEREREJP/SxLYSTBl2z3POvW5m8/ENPQ5wu3Pu54yOM7MwYATQEdgBLDOzmc65tX67bQP6A/886ZzzgMZePWWAjcAcv10GO+c+yygGERERETk7pExsq5YmCYbTJk1m1gIo55yb7Zz7CfjJK7/azAo455ZnUHdLYKNzbrN33ETgeiA1aXLObfW2JadTT09gtnPuSCauR0RERETOQmppkmBKr3vey/glOH7WAK9mou5KwHa/9R1eWVb1BiacVPaSma0yszfMrGBaB5nZ3WYWbWbRcXFx2TitiIiIiOQVKS1NSpokGNJLmoqnNR+TV1YueCH9zcwqAg2Ar/2KHwfqAi2AMsCQtI51zr3vnGvunGtevnz5oMcqIiIiIqGza9cuChQoQNmyZUMdiuRD6SVNpdPZViQTde8EqvitV/bKsuJGYJpzLjGlwDm3y/nE4xukomUW6xQRERGRfGTRokUMGzaMFi1aUKBAZsY5E8ma9D5V35jZS2aWOry4+QwFvstE3cuA2mZWw8wi8XWzm5nF+PpwUtc8r/UJL65uwC9ZrFNERERE8onFixdz1VVXUblyZaZPnx7qcCSfSi9pegSoCWw0sylmNgXYAFwAPJxRxc6548BAfF3r1gGfOufWmNlQM+sKvsEmzGwH0At4z8zWpBxvZtXxtVQtOKnqcWa2GliNr5vgi5m6UhERERHJV5YsWUKXLl2oWLEi3333Heeee26oQ5J8ypxz6e9gVhO4yFtdkzIaXl7SvHlzFx0dHeowRERERCRAli1bRocOHShfvjwLFiygUqXsjDcm8jczW+6ca57WtszM07QZyHOJkoiIiIjkT8uXL6dTp06UK1eOefPmKWGSoNOTciIiIiKSZ/z888907NiRUqVKMW/ePKpUqZLxQSI5pKRJRERERPKElStX0qFDB4oXL868efOoWrVqqEOSs0S6SZOZhZnZr2cqGBERERGRtKxevZorr7ySIkWKMG/ePKpXrx7qkOQsku4zTc65JDNbb2ZVnXPbzlRQIiIiIvK3Q4cOceONN7Jy5UouvPDC1KVevXpceOGFVKhQAb9ZYvKdNWvWcOWVV1KoUCHmzZtHzZo1Qx2SnGUyHAgC3yS3a8wsCjicUuic6xq0qERERERCKDExkXfeeYdGjRrRvn37kMZy5MgRrrvuOhYuXEjPnj3ZsmULY8aM4dChQ6n7lC5dOjWB8k+ozjvvPMLDw/N0QrVu3TquuOIKwsPDmTdvHrVq1Qp1SHIWykzS9HTQoxARERHJJTZt2sTNN9/M0qVLCQ8P54MPPuDWW28NSSzx8fF0796dBQsWMHbsWPr27QuAc46dO3eybt061q5dy7p161i3bh0zZsxg9OjRp9QTGRlJREQEkZGRpyz+5UWLFqVMmTKULl2aMmXKpC7+6ymvCxcuHPTrX79+PVdccQVmxrx586hdu3bQzymSlswMOb7AzKoBtZ1z35hZESAs+KGJiIiInDnOOT7++GMGDhxIWFgYY8aM4ZNPPqFfv37s2rWLwYMHn9EWm8TERG688UbmzJnD//73v9SECcDMqFy5MpUrV6Zjx44nHLd79+7UJCouLo6EhAQSExNJSEjIcDlw4AC///47e/fuZd++fSQlJZ02vkKFClGkSJEsvSfh4eEUK1aMYsWKUbRo0dTXJy9FixalcOHCvPjiiyQnJzN//nzq1KmT9TdRJEAyM7ntXcDdQBnn3PlmVhsY6Zy78kwEGAia3FZERETSs3//fv7xj38wadIk2rVrxyeffELVqlVJSEigf//+TJgwgQcffJDXX3+dAgWCP/jw8ePH6du3L5MnT+btt9/mvvvuC/o5T+ac4+DBg+zduzc1iTr59ZEjR7JUZ2JiIocPH+bQoUOpy8nrx44dS92/QoUKfPfdd1x00UWBvjyRU+RoclvgPqAlsBTAObfBzCoEMD4RERGRkFm4cCG33HILO3fu5KWXXmLIkCGEhfk61URGRjJ27FjOPfdc3njjDXbt2sXHH39MwYIFgxZPcnIyd9xxB5MnT+a1114LScIEvtasEiVKUKJEiTM6Ut3x48c5fPgwhw8fplSpUhQpUuSMnVvkdDKTNMU75xJSml7NLBxIv3lKREREJJdLTExk6NCh/Otf/6JGjRosXryYli1bnrJfgQIFeP3116lUqRL//Oc/iYuLY9q0aZQsWTLgMTnnuOeee/jkk0944YUXeOSRRwJ+jtwuPDyckiVLBuX9FcmuzLQvLzCzJ4DCZtYRmAx8HtywRERERIJn06ZNtG3blhdffJF+/frx888/p5kw+XvkkUf45JNPWLhwIZdddhm7du0KaEzOOQYNGsT777/PE088wVNPPRXQ+kUk+zKTND0GxAGrgf8DvgT0r1hERETyHOccH330EY0bN2b9+vVMmjSJDz/8kOLFi2fq+FtuuYVZs2axceNG2rRpw/r16wMW1+OPP86wYcN46KGHePHFFwNSr4gERmaSpsuBsc65Xs65ns65US6j0SNEREREcpn9+/fTp08f+vfvT9OmTVm5ciU33nhjluvp1KkT8+fP58iRI1xyySUsXbo0x7ENHTqUl19+mXvuuYf//ve/eXpeJZH8KDNJUz9gpZktMbNXzew6Mysd7MBEREREAmHDhg089thj1KlTh88++4yXXnqJ7777jqpVq2a7zubNm7N48WJKlSrF5ZdfzqxZs7Jd1yuvvMJzzz3H7bffzttvv62ESSQXyjBpcs7d5py7AOgBbAdG4OuuJyIiIpIrHT16lHHjxtG+fXsuuOACXnvtNdq0acOPP/7IE088kTo6Xk7UqlWLH374gXr16nH99dfzwQcfZLmOYcOGMWTIEPr06cOoUaPOyHDmIpJ1mZmn6RagLdAA2A0sAhY6534MfniBoXmaREREcm7nzp1UrFgxV3+xX7VqFaNGjWLs2LHs37+fmjVrMmDAAPr370/FihWDcs6DBw/Ss2dP5syZQ5s2bShSpAiRkZEnLBEREaeU/fXXX7z77rt0796dSZMmEREREZT4RCRzcjpP05vAJmAkMM85tzVwoYmIiEheEBMTQ82aNXnjjTe49957Qx3OCQ4ePMiECRMYPXo0y5YtIzIykhtuuIG77rqLyy67LOhJXvHixfn888958sknWb58OceOHePAgQMkJCScsiQmJp6wfsMNNzB+/HglTCK5XIZJk3OunJldBLQDXjKz2sB659ytQY9OREREcoUlS5aQkJDAxIkTc0XS9Ndff7F8+XLGjRvHpEmTOHz4MPXr1+ett97i5ptvpmzZsmc0nsjISF599dUsHeOc0/NLInlEhkmTmZUAqgLVgOpASSA5uGGJiIhIbpIyQtyiRYuIiYnhnHPOOSPnTU5OZuvWraxcuTJ1WbFiBVu3bgWgaNGi9OnThwEDBtCyZcs8lYTkpVhFznaZ6Z63yG952zm3I7ghiYiISG4TFRVFmTJl2Lt3LzNnzuSuu+4K+DmOHj3K6tWrUxOjlStXsmrVKg4ePAj4kowLLriAli1bctddd9GoUSPatWuX6TmWRESyK8OBIFJ3NCsG4Jw7FNSIgkADQYiIiGRfcnIypUuXpk+fPnzzzTfUrl2b2bNnB/QcR44c4aKLLkptQSpevDgNGzakUaNGNG7cmEaNGlG/fn2KFCkS0POKiKTI0UAQZlYf+AQo41u1OOA259wvgQ1TREREcqPffvuNAwcO0KpVK0qUKMGbb77JX3/9RcmSJQN2jhkzZrB161beeustrr32WqpXr56rR+kTkbNLZn4bvQ887Jyr5pyrCjzilYmIiMhZICoqCoCWLVvSo0cPEhMTczSZa1rGjh1LlSpVGDhwIDVr1lTCJCK5SmZ+IxV1zs1LWXHOzQeKBi0iERERyVWWLl1KsWLFqFu3Li1btqRixYpMnTo1YPXHxsby9ddf07dvXyVLIpIrZeY302Yze9rMqnvLU8DmYAcmIiIiuUNUVBTNmzcnLCyMAgUK0L17d2bPns2RI0cCUv+nn35KUlISt9xyS0DqExEJtMwkTXcA5YGpwBSgnFcmIiIi+dyxY8dYuXIlrVq1Si3r0aMHR44cYc6cOQE5x9ixY1MHehARyY1OmzSZWSEzGwS8AKwBWjnnmjnnBjnn9mWmcjPrYmbrzWyjmT2WxvZ2ZvaTmR03s54nbUsysxXeMtOvvIaZLfXqnGRmkZm9WBEREcmalStXkpiYSMuWLVPL2rVrR+nSpZk2bVqO69+wYQNLly5VK5OI5GrptTR9BDQHVgNXAVma5trMwoAR3rH1gD5mVu+k3bYB/YHxaVRx1DnX2Fu6+pW/DLzhnKsF7APuzEpcIiIiknn+g0CkiIiIoGvXrsycOZPExMQc1T9u3DjMjD59+uSoHhGRYEovaarnnLvFOfce0BNol8W6WwIbnXObnXMJwETgev8dnHNbnXOrgOTMVGi+qbOvAD7zij4CumUxLhEREcmkqKgoKlasSKVKlU4o79GjB/v372f+/PnZrts5x9ixY7n88stPqV9EJDdJL2lK/dORc+54NuquBGz3W9/hlWVWITOLNrMlZtbNKysL7PeLJ6t1ioiISBYsXbqUli1b4vu75d86duxI0aJFc9RFb+nSpWzatEld80Qk10svaWpkZge85SDQMOW1mR04A7FV82bk7Qu8aWbnZ+VgM7vbS7qi4+LighOhiIhIPrZ37142bNhwwiAQKQoXLsxVV13FtGnTSE7OVIeRU4wdO5ZChQrRo0ePnIYqIhJUp02anHNhzrkS3lLcORfu97pEJureCVTxW6/slWWKc26n93MzMB9oAuwBSplZeEZ1Oufed841d841L1++fGZPKyIiIp7o6GjgxOeZ/PXo0YM///yTJUuWZLnuxMREJk2aRNeuXSlZsmSO4hQRCbZgziC3DKjtjXYXCfQGZmZwDABmVtrMCnqvywGXAGudcw6Yh+8ZK4DbgBkBj1xERERSB4Fo3rx5mtuvueYaIiMjszXR7Zw5c9i9e7e65olInhC0pMl77mgg8DWwDvjUObfGzIaaWVcAM2thZjuAXsB7ZrbGO/xCINrMVuJLkv7jnFvrbRsCPGxmG/E94/S/YF2DiIjI2SwqKoq6deuetiWoRIkSXHnllUybNg3f3zUzb+zYsZQtW5bOnTsHIlQRkaAKz3iX7HPOfQl8eVLZM36vl+HrYnfycYuBBqepczO+kflEREQkSJxzLF26lC5duqS7X48ePbjrrrtYtWoVjRo1ylTdBw4cYPr06dx+++1ERmq6RRHJ/YLZPU9ERETyqG3bthEbG5vmIBD+unbtSoECBbLURW/atGkcO3ZMXfNEJM9Q0iQiIiKnSGtS27RUqFCBSy+9NEtDj48dO5YaNWrQpk2bHMUoInKmKGkSERGRU0RFRREZGUnDhg0z3LdHjx6sXr2aDRs2ZLjvH3/8wbfffsstt9xyytxPIiK5lZImEREROUVUVBRNmjTJ1DNH3bt3B8hUa9PEiRNxznHzzTfnOEYRkTNFSZOIiIic4Pjx40RHR2fYNS9F1apVadasWaaSprFjx9KiRQvq1KmT0zBFRM4YJU0iIiJygrVr13LkyJEMB4Hw16NHD5YsWcLOnaefx37NmjX8/PPPamUSkTxHSZOIiIicILODQPjr0aMHANOnTz/tPuPGjSMsLIzevXvnKD4RkTNNSZOIiIicICoqilKlSlGrVq1MH1O3bl0uvPDC0w49npyczLhx4+jYsSPnnHNOoEIVETkjlDSJiIjICaKiomjZsmWWR7fr3r07CxYsYM+ePadsW7RoEdu2bdPcTCKSJylpEhERkVSHDx9m9erVWeqal6JHjx4kJSXx+eefn7Jt7NixFC1alG7dugUgShGRM0tJk4iIiKT66aefSE5OztIgECmaNm1K1apVT+miFx8fz+TJk+nevTtFixYNVKgiImeMkiYRERFJlTIIRIsWLbJ8rJnRvXt35syZw6FDh1LLv/zyS/bv369R80Qkz1LSJCIiIqmioqKoVq1atgdr6NGjB/Hx8cyePTu1bOzYsVSoUIEOHToEKkwRkTNKSZOIiIikShkEIrsuueQSypcvn9pFb9++fXzxxRf06dOH8PDwQIUpInJGKWkSERERAGJjY9m6dWuOkqawsDCuv/56Zs2aRXx8PJ999hkJCQkaNU9E8jQlTSIiIgL8/TxTdgaB8NejRw8OHjzIt99+y9ixY6lTpw7NmjULRIgiIiGhpElEREQAX9JUoEABmjZtmqN6rrjiCkqUKMGbb77J999/zy233JLlOZ9ERHITJU0iIiIC+JKm+vXr53hY8IIFC3Lttdcyd+5cAPr27RuI8EREQkZJk4iIiOCcy/EgEP66d+8OwMUXX0zNmjUDUqeISKgoaRIRERE2bdrEvn37ApY0denShdq1a/PAAw8EpD4RkVDS2J8iIiLC0qVLgZwPApGiWLFi/PbbbwGpS0Qk1NTSJCIiIkRFRVGkSBHq1asX6lBERHIdJU0iIiJCVFQUzZo10wS0IiJpUNIkIiJylktISODnn38O2PNMIiL5jZImERGRs9zq1auJj49X0iQichpKmkRERM5ygR4EQkQkv1HSJCIicpaLioqiQoUKVK1aNdShiIjkSkqaREREznIpk9qaWahDERHJlYKaNJlZFzNbb2YbzeyxNLa3M7OfzOy4mfX0K29sZj+a2RozW2VmN/ltG2NmW8xshbc0DuY1iIiI5Gd//fUXv/76q55nEhFJR9DGFTWzMGAE0BHYASwzs5nOubV+u20D+gP/POnwI0A/59wGMzsPWG5mXzvn9nvbBzvnPgtW7CIiImeL5cuX45xT0iQiko5gTsbQEtjonNsMYGYTgeuB1KTJObfV25bsf6Bz7je/13+YWSxQHtgfxHhFRETOOimDQLRo0SLEkYiI5F7B7J5XCdjut77DK8sSM2sJRAKb/Ipf8rrtvWFmBXMWpoiIyNkrKiqK2rVrU6ZMmVCHIiKSa+XqgSDMrCLwCXC7cy6lNepxoC7QAigDDDnNsXebWbSZRcfFxZ2ReEVERPKalEEgRETk9IKZNO0EqvitV/bKMsXMSgCzgCedc0tSyp1zu5xPPPAhvm6Ap3DOve+ca+6ca16+fPlsXYCIiEh+tnPnTv744w8lTSIiGQhm0rQMqG1mNcwsEugNzMzMgd7+04CPTx7wwWt9wnzjonYDfglk0CIiImeLqKgoACVNIiIZCFrS5Jw7DgwEvgbWAZ8659aY2VAz6wpgZi3MbAfQC3jPzNZ4h98ItAP6pzG0+DgzWw2sBsoBLwbrGkREJG86duwY06ZN44knnmDu3LkkJiaGOqRcaenSpURERNC4ceNQhyIikquZcy7UMQRd8+bNXXR0dKjDkHzOOcfMmTO59NJLKVu2bKjDETnrJCYm8u233zJhwgSmTZvGwYMHU7eVLl2arl270qNHDzp16kShQoVCGGnuccUVV3Dw4EGWLVsW6lBERELOzJY755qntS1XDwQhkpdMnz6dbt26cdddd4U6FJGzRnJyMgsWLOCee+7hvPPO46qrrmLGjBn07NmTr7/+moMHDzJjxgyuu+46ZsyYwfXXX0/58uXp3bs3n376KYcOHQr1JZxxzjni4uJYsmQJ0dHR6ponIpIJamkSCYBDhw5Rr149YmJiSEhI4IcffuDiiy8OdVgi+ZJzjujoaCZMmMCnn37Kzp07KVKkCF27dqV379506dKFggVPnY0iISGB+fPnM2XKFKZPn05sbCwFCxakc+fO3HDDDVx33XWULl06y7EcOnSIvXv3snfvXvbt25fu6/3795OV/3fNjHLlynHOOedw7rnnpvmzXLlyFChw4t9Ak5OT2blzJxs3bmTTpk1s2rTphNcHDhxI3ffTTz+lV69eWbpuEZH8KL2WJiVNIgHw6KOP8uqrr/L111/Tr18/ateuzffff49vvBIRyYzExEQOHz7MoUOHTlj8yzZt2sSnn37Kpk2biIiI4KqrrqJPnz5cd911FC1aNNPnSkpK4ocffmDq1KlMnTqV7du3Ex4eTps2bShUqBAJCQmnLImJiaeUxcfHk5SUdNrzREZGUqZMmdSlZMmShIWFZSnO3bt3ExMTw59//smxY8dO2ScsLIwKFSpwzjnnUKZMGf744w+2bNlCfHx86j7h4eHUqFGD888/n1q1aqX+vOCCC7jgggsyHY+ISH6mpElJkwTRL7/8QpMmTbjtttsYPXo0I0eO5J577mHGjBl07do11OGJ5FpTpkxhyJAh7Nu3j0OHDpGQkJDhMQUKFODKK6+kd+/edO/ePcstQ2lJabmaMmUKCxYswMyIiIggMjIy3SUiIoKCBQtSunRpSpcufUJylLJeuHDhgP3xxDnHgQMHUhOok3/++eef7Nmzh4oVK3L++eefkCBVqVKF8PDwgMQhIpJfKWlS0iRB4pzjsssuY82aNaxfv55y5cqRmJhI/fr1CQsLY9WqVfqiIpKG+fPn07lzZy688EIuvfRSihUrRrFixShatGjq67TWS5cuTfHixUMdvoiI5EPpJU36NieSAx9//DELFy5k9OjRlCtXDoCIiAj+/e9/c8MNNzBmzBgGDBgQ4ihFcpfVq1fTrVs3zj//fL777jvKlCkT6pBERETSpZYmkWzau3cvderUoXbt2ixatOiEB7Gdc1xyySX8/vvvbNiwgSJFioQwUpHcY8eOHbRu3Zrk5GSWLFlC1apVQx2SiIgIoCHHRYLiiSeeYN++fYwcOfKUkavMjFdeeYU//viDN998MzQBSr73n//8h7Zt2+aZiVv/+usvrrrqKg4cOMDs2bOVMImISJ6hliYJmoSEBL799luOHz+e7oPUJ6+fnICkxzmX5ohWaZUlJCRgZlx55ZU5nthy6dKltGnThkGDBvH666+fdr/rr7+e+fPns2nTptTueyKBsGLFCpo3b05SUhIffPABt99+e6hDSld8fDxXXXUVCxcuZPbs2XTo0CHUIYmIiJxAA0EoaTqjEhMTGTNmDC+++CLbtm0LdTinaNOmDTNmzKB8+fLZOv748eO0bNmSmJgYfv3113QfSl+7di0NGjTg/vvvV4uTBExSUhJt2rTh999/p0KFChw7dox169bl2kFHkpOTueWWW5gwYQIff/wxt956a6hDEhEROYUGgpAz4vjx43zyySe88MILbNmyhZYtWzJ8+HAqVaqUZqvP6VqGsprIZ2ZY4JTXa9eu5f/+7/+4+OKLmT17NrVq1crydb777rv8/PPPfPrppxmO4lWvXj3uuOMO3nnnHR588EFq1KiR5fOJnOydd95h2bJljB8/noIFC3LDDTcwadIkbr755lCHlqbHHnuMCRMm8K9//UsJk4iI5ElqaZIcO378OOPHj2fo0KFs2rSJZs2a8fzzz3P11Vfnysldf/zxR6677jrMjJkzZ9KmTZtMH7tr1y7q1q1LmzZtmD17dqaub+fOndSuXZvu3bszbty4nIQuwo4dO7jwwgu55JJLmD17Ns45GjVqRFJSEr/88kuWureeCcOHD+eBBx7gnnvuYcSIEbnyd4KIiAhoIAgJkqSkJMaPH89FF13EbbfdRvHixZkxYwbLli3jmmuuybVfjtq0acOPP/5IyZIlueKKK5g2bVqmj33kkUeIj4/n7bffzvT1VapUiUGDBjF+/Hh++umn7IYtAsD9999PUlIS7777LmZGgQIFePLJJ1m3bh1Tp04NdXgnmDp1Kg8++CDXX389w4cPz7W/E0RERDKipEmyLDk5mUmTJtGgQQNuvvlmChYsyNSpU1m+fDldu3bNE1+MateuzY8//kijRo244YYbGDZsWIbHfPPNN0yYMIHHH388y936hgwZQtmyZRkyZEh2QxZh+vTpTJ8+neeee+6Erp69evWiTp06vPjii1nu3hosP/zwAzfffDOtWrVi/PjxhIWFhTokERGRbFPSJJmWnJzMlClTaNSoEb1798bM+PTTT1mxYgXdu3fPdd2CMlK+fHm+++47unXrxoMPPsjDDz9McnJymvvGx8dz3333UatWrWwlPiVLluSpp57im2++Yc6cOTkNXc5CBw4cYODAgTRs2JCHHnrohG1hYWE88cQTrFy5ks8//zxEEf7t119/5brrrqNKlSp8/vnnmqdMRETyvLz1LVdC4uDBgwwfPpw6derQs2dPEhMTmTBhAqtWraJXr155LlnyV6RIESZPnswDDzzAG2+8wY033sjRo0dP2e/VV1/lt99+Y8SIEdkervyee+6hevXqDBky5LTJmcjpPPXUU/zxxx+MGjWKiIiIU7b37duXGjVq8MILL4S0tenPP/+kS5cuRERE8NVXX2mofRERyRfy7rddCbqtW7fyyCOPULlyZR544AHKly/PxIkTWbNmDb1798433W3CwsJ46623eP3115k6dSodOnRg9+7dqds3b97MSy+9RK9evejUqVO2z1OwYEFeeuklVqxYwfjx4wMRupwloqKiePvtt7nvvvto2bJlmvuEh4fz+OOPEx0dzddff32GI/Q5ePAgV199Nbt372bWrFnUrFkzJHGIiIgEmkbPkxM45/jhhx948803mTZtGgUKFKBXr148+OCDtGrVKtThBd1nn33GLbfcQtWqVZk9ezY1a9bk2muv5fvvv+fXX3+lUqVKOao/OTmZFi1asGfPHn799dccT7Ir+V9iYiItWrRg9+7drF27lhIlSpx234SEBGrVqkWVKlVYtGjRGX2+cN26dfTs2ZP169czc+ZMrr766jN2bhERkUDQ6HmSoYSEBMaOHUuLFi1o27Yt8+bNY8iQIWzZsoXx48efFQkTQM+ePfnuu+/Yu3cvrVu35rnnnuPLL79k6NChOU6YAAoUKMDLL7/M77//zrvvvhuAiCW/e/PNN1m5ciXDhw9PN2EC35xlQ4YMYfHixcyfP//MBAiMHz+eFi1aEBcXx1dffaWESURE8h21NIVAUlIShw8f5tChQxw6dOiE1yevx8fHU6RIEYoVK0axYsUoWrRo6uuT1wsXLpzl54vi4uJ47733GDFiBH/++Sd169Zl0KBB3HrrrWf1w9u//fYbV111FZs3b6Zhw4YsX76c8PDAzQXduXNnoqOj2bRpE6VKlQpYvZK/bNmyhYsuuohOnToxffr0TB1z7NgxatasSd26dfnuu++CGt+xY8d46KGHGDlyJJdeeikTJ04MyB8XREREQiG9lqbAfQuUDL3//vs8+OCDHDt2LCj1mxmFChXKUuJ07NgxkpKS6NKlC4MGDaJjx455emCHQLngggv48ccfefrpp7nvvvsCmjABvPzyyzRt2pSXX36Zf//73wGtW/IH5xz33nsvYWFhDB8+PNPHFSpUiMGDB/Pwww/zww8/cMkllwQlvs2bN9OrVy9++uknHn30UV566aWA/zsRERHJLdTSdAYtXryY6dOnn9JalF4LUmRkJEePHs2wRSrl9eHDh7MUU5EiRejTpw8XXnhhkK5aTufWW2/ls88+Y9KkSZQoUYLIyMgTloiIiFPKIiMjs5TUOuc4duzYaVs10yorVKgQZcqUoXTp0pQpU+aU14ULF872szLJyclBH9mtQIECeWKusIxMnDiRPn368NZbb/HAAw9k6djDhw9To0YNmjZtyldffRXw2KZPn07//v0xMz766CO6du0a8HOIiIicaem1NClpEgmRrVu3Ur9+/SwnusFUtGhR4uPjOX78+Gn3iYyMPCGZCg8PJyEhIc0lMTHxhPX06g0UMzvtHyPSKmvVqhUdO3YMelxZsW/fPurWrUu1atX48ccfszVS5X/+8x8ef/xxoqKiaNGiRUDiSkxM5LHHHuP111+nefPmTJ48merVqwekbhERkVBT0qSkSXKpXbt2sWXLlkwlHAkJCcTHx2e5paZQoUJZeibOOcehQ4fYu3cv+/btY+/evem+Tk5OznQrWURERNCHqk9ISDhtq9rJ5QkJCQDcdNNNDBs2jAoVKgQ1tsy6++67+eCDD4iOjqZx48bZquPgwYNUq1aNtm3bMmPGjBzHtH37dm666SZ+/PFHBg4cyGuvvUbBggVzXK+IiEhuoWeaRHKpihUrUrFixVCHcQIzo3jx4hQvXpxq1aqFOpygOnr0KP/973954YUXmDt3Lm+88Qa33nprSLv3LVy4kFGjRjF48OBsJ0wAxYsXZ9CgQTz77LOsXLmSRo0aZbuur7/+mptvvpn4+HgmTpzITTfdlO26RERE8iK1NInIWW/dunUMGDCAxYsX07lzZ0aOHBmSbmfx8fE0adKEo0eP8ssvv1C0aNEc1bd//36qVatGp06dmDx5cpaPT0pK4vnnn+fFF1+kfv36TJ48mTp16uQoJhERkdxK8zSJiKTjwgsvZOHChQwfPpwffviB+vXr89Zbb5GUlHTGYli9ejW9e/dm3bp1vPvuuzlOmABKlSrF/fffz5QpU1i7dm2mjzt+/DiffPIJ9evX54UXXqB///4sWbJECZOIiJy1lDSJiOAbdW/gwIGsWbOGdu3aMWjQIC699FLWrFkTtHM651iwYAHXXHMNDRs2ZM6cOQwdOpQuXboE7ByDBg2iSJEi/Otf/8pw3/j4eEaNGkWdOnXo168fkZGRTJkyhQ8++OCsnrdNREQkqEmTmXUxs/VmttHMHktjezsz+8nMjptZz5O23WZmG7zlNr/yZma22qtzmOWHsYVFJNeoWrUqs2bNYuzYsWzYsIEmTZrw/PPPpw4aEQhJSUlMmTKF1q1b0759e5YtW8aLL77I9u3befrppwN2HoBy5cpx7733MmHCBDZs2JDmPkePHmX48OHUqlWLu+++m7JlyzJz5kxWrFhBjx49AhqPiIhIXhS0pMnMwoARwFVAPaCPmdU7abdtQH9g/EnHlgGeBVoBLYFnzay0t/ld4C6gtrcE7k+yIiL4BsO4+eabWbduHb169eK5556jadOmLFmyJEf1Hj16lJEjR1K3bl169uzJ3r17GTlyJL///jtPPvkkZcqUCdAVnOjhhx8mMjLylImUDx48yCuvvEL16tV54IEHqFmzJnPmzGHp0qVcd911+WK+KxERkUAI5uh5LYGNzrnNAGY2EbgeSO1Y75zb6m1LPunYzsBc59xeb/tcoIuZzQdKOOeWeOUfA92A2UG8DhE5S5UvX55x48bRt29f7rnnHi6++GK6detG7dq1qVKlClWrVk39WaZMmdMmGXv37uWdd95h2LBhxMXF0aJFCz777DO6desW9CHYAc4991zuvvtu3nnnHZ555hlKlizJ8OHDefPNN9m3bx+dOnXiySefpF27dkGPRUREJC8KZtJUCdjut74DX8tRdo+t5C070igXEQmaa665hjVr1vDUU0/xxRdfMGvWrFO66xUuXPiEJCrl56pVqxg9ejSHDx/m6quv5tFHH6Vdu3ZnvBXn0UcfZeTIkfTo0YONGzdy8OBBunbtypNPPknLli3PaCwiIiJ5Tb6dp8nM7gbuBt8zCiIiOVG8eHHeeust3nrrLZKTk4mNjWX79u1s27btlJ+zZ89m165dAISHh9O3b1/++c9/0qBBg5DFX6lSJe6++25GjBjBjTfeyBNPPEHDhg1DFo+IiEheEsykaSdQxW+9sleW2WPbn3TsfK+8cmbqdM69D7wPvnmaMnleEZEMFShQgHPPPZdzzz2XFi1apLlPQkICO3fupGjRolSoUOEMR5i2119/naeeeopzzjkn1KGIiIjkKcEcPW8ZUNvMaphZJNAbmJnJY78GOplZaW8AiE7A1865XcABM2vtjZrXD5gRjOBFRHIiMjKSGjVq5JqECSAiIkIJk4iISDYELWlyzh0HBuJLgNYBnzrn1pjZUDPrCmBmLcxsB9ALeM/M1njH7gVewJd4LQOGpgwKAdwLjAY2ApvQIBAiIiIiIhJE5lz+77nWvHlzFx0dHeowREREREQklzKz5c655mltC+rktiIiIiIiInmdkiYREREREZF0KGkSERERERFJh5ImERERERGRdChpEhERERERSYeSJhERERERkXQoaRIREREREUmHkiYREREREZF0nBWT25pZHPB7qOPwlAN2hzoICSrd4/xN9zd/0/3N/3SP8zfd3/wvmPe4mnOufFobzoqkKTcxs+jTzTQs+YPucf6m+5u/6f7mf7rH+Zvub/4Xqnus7nkiIiIiIiLpUNIkIiIiIiKSDiVNZ977oQ5Agk73OH/T/c3fdH/zP93j/E33N/8LyT3WM00iIiIiIiLpUEuTiIiIiIhIOpQ0nUFm1sXM1pvZRjN7LNTxSM6Z2QdmFmtmv/iVlTGzuWa2wftZOpQxSvaZWRUzm2dma81sjZk96JXrHucDZlbIzKLMbKV3f5/3ymuY2VLvd/UkM4sMdaySfWYWZmY/m9kX3rrubz5iZlvNbLWZrTCzaK9Mv6PzCTMrZWafmdmvZrbOzNqE6v4qaTpDzCwMGAFcBdQD+phZvdBGJQEwBuhyUtljwLfOudrAt9665E3HgUecc/WA1sB93r9b3eP8IR64wjnXCGgMdDGz1sDLwBvOuVrAPuDO0IUoAfAgsM5vXfc3/7ncOdfYbxhq/Y7OP94CvnLO1QUa4fu3HJL7q6TpzGkJbHTObXbOJQATgetDHJPkkHPue2DvScXXAx95rz8Cup3JmCRwnHO7nHM/ea8P4vtlXQnd43zB+RzyViO8xQFXAJ955bq/eZiZVQauAUZ764bu79lAv6PzATMrCbQD/gfgnEtwzu0nRPdXSdOZUwnY7re+wyuT/Occ59wu7/WfwDmhDEYCw8yqA02Apege5xte160VQCwwF9gE7HfOHfd20e/qvO1N4FEg2Vsvi+5vfuOAOWa23Mzu9sr0Ozp/qAHEAR96XWxHm1lRQnR/lTSJBJHzDU+pISrzODMrBkwBBjnnDvhv0z3O25xzSc65xkBlfD0C6oY2IgkUM7sWiHXOLQ91LBJUlzrnmuJ7/OE+M2vnv1G/o/O0cKAp8K5zrglwmJO64p3J+6uk6czZCVTxW6/slUn+E2NmFQG8n7EhjkdywMwi8CVM45xzU71i3eN8xuvyMQ9oA5Qys3Bvk35X512XAF3NbCu+LvFX4Hs+Qvc3H3HO7fR+xgLT8P3xQ7+j84cdwA7n3FJv/TN8SVRI7q+SpjNnGVDbG7UnEugNzAxxTBIcM4HbvNe3ATNCGIvkgPf8w/+Adc651/026R7nA2ZW3sxKea8LAx3xPbc2D+jp7ab7m0c55x53zlV2zlXH93/ud865m9H9zTfMrKiZFU95DXQCfkG/o/MF59yfwHYzq+MVXQmsJUT3V5PbnkFmdjW+/tVhwAfOuZdCG5HklJlNANoD5YAY4FlgOvApUBX4HbjROXfyYBGSB5jZpcBCYDV/PxPxBL7nmnSP8zgza4jvIeIwfH9E/NQ5N9TMauJrmSgD/Azc4pyLD12kklNm1h74p3PuWt3f/MO7l9O81XBgvHPuJTMri35H5wtm1hjfQC6RwGbgdrzf15zh+6ukSUREREREJB3qniciIiIiIpIOJU0iIiIiIiLpUNIkIiIiIiKSDiVNIiIiIiIi6VDSJCIiIiIikg4lTSIikueZWVkzW+Etf5rZTu/1ITN7J9TxiYhI3qYhx0VEJF8xs+eAQ86510Idi4iI5A9qaRIRkXzLzNqb2Rfe6+fM7CMzW2hmv5tZDzN7xcxWm9lXZhbh7dfMzBaY2XIz+9rMKob2KkREJNSUNImIyNnkfOAKoCswFpjnnGsAHAWu8RKn4UBP51wz4APgpVAFKyIiuUN4qAMQERE5g2Y75xLNbDUQBnzlla8GqgN1gPrAXDPD22dXCOIUEZFcREmTiIicTeIBnHPJZpbo/n6wNxnf/4kGrHHOtQlVgCIikvuoe56IiMjf1gPlzawNgJlFmNlFIY5JRERCTEmTiIiIxzmXAPQEXjazlcAK4OKQBiUiIiGnIcdFRERERETSoZYmERERERGRdChpEhERERERSYeSJhERERERkXQoaRIREREREUmHkiYREREREZF0KGkSERERERFJh5ImERERERGRdChpEhERERERScf/A3c0hie6b0EIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>**Natural Language Processing(NLP)**</center>\n",
        "\n",
        "**--> Applying RNNs to Text**"
      ],
      "metadata": {
        "id": "LqkVREMt_fg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing -> Sequential Data**\n",
        "\n",
        "\n",
        "*   Tokenization\n",
        "*   Padding\n",
        "*   Lowercase conversion\n",
        "*   Removing stop words\n",
        "*   Removing punctuation\n",
        "*   Stemming\n",
        "\n"
      ],
      "metadata": {
        "id": "H8T2rETgRSQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Cleaning** --> Conversion to lowercase, removval of punctuation marks, so on."
      ],
      "metadata": {
        "id": "mdP_SLKJTBC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a function to return list of cleaned words:**"
      ],
      "metadata": {
        "id": "-9xezEMbTRDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to clean text\n",
        "def clean_text(txt):\n",
        "  # remove punctuation from the text and convert it to lowercase\n",
        "  txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "\n",
        "  # encode the text as utf-8 and decode it as ascii, ignoring any errors\n",
        "  txt = txt.encode(\"utf-8\").decode(\"ascii\", \"ignore\")\n",
        "\n",
        "  # return the cleaned text\n",
        "  return take\n",
        "\n",
        "# create a corpus by applying the clean_text function to all headlines\n",
        "# corpus = [clean_text(x) for x in all_headlines]"
      ],
      "metadata": {
        "id": "CTk7VjB29YXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating a Sequence and Tokenization:**"
      ],
      "metadata": {
        "id": "RTmd-VCyVBxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "QHamFLNdUr7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "xHtLEJ-3Vq_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the function to get a sequence of tokens from the corpus\n",
        "def get_seq_of_tokens(corpus):\n",
        "  # fit the tokenizer on the corpus\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "  # get the total number of words in the tokenizer's word index\n",
        "  all_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # initialize an empty list to store the input sequences\n",
        "  input_sequences = []\n",
        "\n",
        "  # iterate over each line in the corpus\n",
        "  for line in corpus:\n",
        "    # convert the line to a sequence of tokens using the tokenizer\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # iterate over the token_list\n",
        "    for i in range(1, len(token_list)):\n",
        "      # create an n-gram sequence from the token list\n",
        "      n_gram_sequence = token_list[:i+1]\n",
        "\n",
        "      # append the n-gram sequence to the input sequences list\n",
        "      input_sequences.append(n_gram_sequence)\n",
        "\n",
        "      # return the input sequences and total number of words\n",
        "      return input_sequences, all_words\n",
        "\n",
        "# get the input sequences and total number of words from the corpus\n",
        "# inp_sequences, all_words = get_seq_of_tokens(corpus)\n",
        "\n",
        "# print the first 10 input sequences\n",
        "# inp_sequences[:10]"
      ],
      "metadata": {
        "id": "9q-J6BUaWB-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Padding Sequences** --> Transform all the input sentences to fixed lenght by either adding padding to shorter sentences or truncate longer ones."
      ],
      "metadata": {
        "id": "krT_CLKsryY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "kfWQhPjoX0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes input_sequences and generate the padded version of it:"
      ],
      "metadata": {
        "id": "d-jlOEwjt1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate padded sequences from the input sequences\n",
        "def generate_padded_sequences(input_sequences):\n",
        "\n",
        "    # Get the maximum sequence length\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "    # Pad the input sequences using the maximum sequence length\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    # Split the input sequences into predictors and label\n",
        "    predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "\n",
        "    # Convert the label to categorical format\n",
        "    label = ku.to_categorical(label, num_classes=all_words)\n",
        "\n",
        "    # Return the predictors, label and maximum sequence length\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "# Generate the padded sequences from the input sequences\n",
        "# predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "metadata": {
        "id": "Da4zMtTOttzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building an RNN with an LSTM layer for Natural Language Processing**\n",
        "\n",
        "--> Using **LSTM Model** for predicting the next word of a text."
      ],
      "metadata": {
        "id": "uhMJQIp0yRIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required Libraries"
      ],
      "metadata": {
        "id": "I9EA2E0Xziw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pad_sequences function from Keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Import the Embedding, LSTM, Dense and Dropout layers from Keras\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Import the Tokenizer and EarlyStopping classes from Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Import the Sequential model class from Keras\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import the utils module from Keras as ku\n",
        "import keras.utils as ku \n",
        "\n",
        "# Import the pandas library as pd\n",
        "import pandas as pd\n",
        "# Import the numpy library as np\n",
        "import numpy as np\n",
        "\n",
        "# Import the string and os modules\n",
        "import string, os \n",
        "\n",
        "# Import the warnings module\n",
        "import warnings\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "azxfA8qLvBsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and iterate over the files contained in the folder, and extract the headlines. Remove all the headlines with the unknown value."
      ],
      "metadata": {
        "id": "YpbjS99M2zk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the current directory\n",
        "curr_dir = '/content/'\n",
        "\n",
        "# Initialize an empty list to store all headlines\n",
        "all_headlines = []\n",
        "\n",
        "# Iterate over the files in the current directory\n",
        "for filename in os.listdir(curr_dir):\n",
        "\n",
        "    # Check if the filename contains 'Articles'\n",
        "    if 'Articles' in filename:\n",
        "\n",
        "        # Read the file as a DataFrame\n",
        "        article_df = pd.read_csv(curr_dir + filename)\n",
        "\n",
        "        # Extend the all_headlines list with the values from the headline column\n",
        "        all_headlines.extend(list(article_df.headline.values))\n",
        "        # Break out of the loop\n",
        "        break\n",
        "# Filter out headlines with the value \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "\n",
        "# Get the length of the all_headlines list\n",
        "len(all_headlines)"
      ],
      "metadata": {
        "id": "SDbivHCt04DA",
        "outputId": "d6015db2-3622-4b90-b3fe-6a93dc7c006d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "831"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display first 5 texts\n",
        "all_headlines[:5]"
      ],
      "metadata": {
        "id": "z4Rgjvdb5xTE",
        "outputId": "18ab759f-873e-43ae-dcad-1122ba0b73b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Finding an Expansive View  of a Forgotten People in Niger',\n",
              " 'And Now,  the Dreaded Trump Curse',\n",
              " 'Venezuelas Descent Into Dictatorship',\n",
              " 'Stain Permeates Basketball Blue Blood',\n",
              " 'Taking Things for Granted']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to clean the words, convert into lowercase and encode it with \"utf-8\" for character standardization. Return the list containing cleaned words."
      ],
      "metadata": {
        "id": "aXMYasM46eFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to clean text\n",
        "def clean_text(txt):\n",
        "\n",
        "    # Remove punctuation from the text and convert it to lowercase\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "\n",
        "    # Encode the text as utf-8 and decode it as ascii, ignoring any errors\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "\n",
        "    # Return the cleaned text\n",
        "    return txt \n",
        "\n",
        "# Create a corpus by applying the clean_text function to all headlines\n",
        "corpus = [clean_text(x) for x in all_headlines]\n",
        "\n",
        "# Print the first 10 elements of the corpus\n",
        "for text in corpus[:10]:\n",
        "  print(f\"--> {text}\")"
      ],
      "metadata": {
        "id": "aAZWDya76DOK",
        "outputId": "30461d15-bbd2-497d-b7ff-83a561dd1af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> finding an expansive view  of a forgotten people in niger\n",
            "--> and now  the dreaded trump curse\n",
            "--> venezuelas descent into dictatorship\n",
            "--> stain permeates basketball blue blood\n",
            "--> taking things for granted\n",
            "--> the caged beast awakens\n",
            "--> an everunfolding story\n",
            "--> oreilly thrives as settlements add up\n",
            "--> mouse infestation\n",
            "--> divide in gop now threatens trump tax plan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes corpus of text as input and coverts it to a sequence of tokens using the tokenizer. Returns a list of input sequences and the total number of words in the tokenizer's word index"
      ],
      "metadata": {
        "id": "7osC6-Xt-6WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Define a function to get a sequence of tokens from the corpus\n",
        "def get_seq_of_tokens(corpus):\n",
        "\n",
        "    # Fit the tokenizer on the corpus\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    # Get the total number of words in the tokenizer's word index\n",
        "    all_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Initialize an empty list to store the input sequences\n",
        "    input_sequences = []\n",
        "\n",
        "    # Iterate over each line in the corpus\n",
        "    for line in corpus:\n",
        "\n",
        "        # Convert the line to a sequence of tokens using the tokenizer\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "        # Iterate over the token list\n",
        "        for i in range(1, len(token_list)):\n",
        "\n",
        "            # Create an n-gram sequence from the token list\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "\n",
        "            # Append the n-gram sequence to the input sequences list\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    # Return the input sequences and the total number of words\n",
        "    return input_sequences, all_words\n",
        "\n",
        "# Get the input sequences and total number of words from the corpus\n",
        "inp_sequences, all_words = get_seq_of_tokens(corpus)\n",
        "\n",
        "# Print the first 10 input sequences\n",
        "for inp_seq in inp_sequences[:10]:\n",
        "  print(f\"--> {inp_seq}\")"
      ],
      "metadata": {
        "id": "ro8iocJp7u8r",
        "outputId": "a0e48fa2-c47e-4979-d0be-7085a60859b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> [169, 17]\n",
            "--> [169, 17, 665]\n",
            "--> [169, 17, 665, 367]\n",
            "--> [169, 17, 665, 367, 4]\n",
            "--> [169, 17, 665, 367, 4, 2]\n",
            "--> [169, 17, 665, 367, 4, 2, 666]\n",
            "--> [169, 17, 665, 367, 4, 2, 666, 170]\n",
            "--> [169, 17, 665, 367, 4, 2, 666, 170, 5]\n",
            "--> [169, 17, 665, 367, 4, 2, 666, 170, 5, 667]\n",
            "--> [6, 80]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a funtion for **Padding sentences** so that each input sentences are of fixed length, either by adding padding to shorter sentences or by truncating longer ones."
      ],
      "metadata": {
        "id": "19B1cWfeApWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate padded sequences from the input sequences\n",
        "def generate_padded_sequences(input_sequences):\n",
        "\n",
        "    # Get the maximum sequence length\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "    # Pad the input sequences using the maximum sequence length\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    # Split the input sequences into predictors and label\n",
        "    predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "\n",
        "    # Convert the label to categorical format\n",
        "    label = ku.to_categorical(label, num_classes=all_words)\n",
        "    \n",
        "    # Return the predictors, label and maximum sequence length\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "# Generate the padded sequences from the input sequences\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "metadata": {
        "id": "r_iUpWaoAVqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the NLP model for training by adding Embedding, LSTM layer & Dropout layer. Compile the model.**"
      ],
      "metadata": {
        "id": "ikzGppy0CzP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to create a model\n",
        "def create_model(max_sequence_len,  all_words):\n",
        "\n",
        "  # calculate the input length\n",
        "  input_len = max_sequence_len - 1\n",
        "\n",
        "  # create a Sequential model\n",
        "  model = Sequential()\n",
        "\n",
        "  # add an Embedding layer to the model\n",
        "  model.add(Embedding(all_words, 10, input_length=input_len))\n",
        "\n",
        "  # add an LSTM layer to the model\n",
        "  model.add(LSTM(100))\n",
        "\n",
        "  # add a dropout layer to prevent overfitting\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  # add a Dense layer with a softmax activation function to the model\n",
        "  model.add(Dense(all_words, activation=\"softmax\"))\n",
        "\n",
        "  # finally, compile the model with appropriate loss and optimizer\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=\"categorical_crossentropy\"\n",
        "  )\n",
        "\n",
        "  # return the model\n",
        "  return model\n",
        "\n",
        "# create the model by calling the create_model function\n",
        "model = create_model(max_sequence_len, all_words)"
      ],
      "metadata": {
        "id": "Gr-z-M7OCS_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the summary architecture of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "nPpMY7pDE8DE",
        "outputId": "b1cfa3c5-0365-4a36-8654-92050e12686c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 18, 10)            24220     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2422)              244622    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,242\n",
            "Trainable params: 313,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model with **Predictors** & **target** data."
      ],
      "metadata": {
        "id": "XfvJhShJGjfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(\n",
        "    predictors,\n",
        "    label,\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "id": "nEFhX_E0HTOf",
        "outputId": "d06d332a-183c-4bc5-e3c5-f90138431641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.5840\n",
            "Epoch 2/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.5579\n",
            "Epoch 3/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.5405\n",
            "Epoch 4/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.5203\n",
            "Epoch 5/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.5043\n",
            "Epoch 6/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.4972\n",
            "Epoch 7/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.4712\n",
            "Epoch 8/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 1.4639\n",
            "Epoch 9/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.4350\n",
            "Epoch 10/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.4168\n",
            "Epoch 11/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3993\n",
            "Epoch 12/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3883\n",
            "Epoch 13/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3709\n",
            "Epoch 14/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3713\n",
            "Epoch 15/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3320\n",
            "Epoch 16/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 1.3243\n",
            "Epoch 17/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.3119\n",
            "Epoch 18/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.2970\n",
            "Epoch 19/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.2767\n",
            "Epoch 20/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 1.2717\n",
            "Epoch 21/100\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 1.2516\n",
            "Epoch 22/100\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.2366\n",
            "Epoch 23/100\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 1.2272\n",
            "Epoch 24/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.2158\n",
            "Epoch 25/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.1912\n",
            "Epoch 26/100\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.1826\n",
            "Epoch 27/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.1840\n",
            "Epoch 28/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.1542\n",
            "Epoch 29/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.1409\n",
            "Epoch 30/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 1.1306\n",
            "Epoch 31/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.1161\n",
            "Epoch 32/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0983\n",
            "Epoch 33/100\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.0850\n",
            "Epoch 34/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.0873\n",
            "Epoch 35/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0668\n",
            "Epoch 36/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 1.0579\n",
            "Epoch 37/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0472\n",
            "Epoch 38/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0390\n",
            "Epoch 39/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0176\n",
            "Epoch 40/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0087\n",
            "Epoch 41/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 1.0038\n",
            "Epoch 42/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9996\n",
            "Epoch 43/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9947\n",
            "Epoch 44/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9720\n",
            "Epoch 45/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9492\n",
            "Epoch 46/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9626\n",
            "Epoch 47/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.9405\n",
            "Epoch 48/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.9271\n",
            "Epoch 49/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.9187\n",
            "Epoch 50/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9104\n",
            "Epoch 51/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.9032\n",
            "Epoch 52/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8934\n",
            "Epoch 53/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8720\n",
            "Epoch 54/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8758\n",
            "Epoch 55/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8664\n",
            "Epoch 56/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8605\n",
            "Epoch 57/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8429\n",
            "Epoch 58/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8358\n",
            "Epoch 59/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8223\n",
            "Epoch 60/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8154\n",
            "Epoch 61/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.8260\n",
            "Epoch 62/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.8145\n",
            "Epoch 63/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.8000\n",
            "Epoch 64/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.7960\n",
            "Epoch 65/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7793\n",
            "Epoch 66/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7672\n",
            "Epoch 67/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7663\n",
            "Epoch 68/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7634\n",
            "Epoch 69/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7440\n",
            "Epoch 70/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7426\n",
            "Epoch 71/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7369\n",
            "Epoch 72/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.7388\n",
            "Epoch 73/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7221\n",
            "Epoch 74/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7144\n",
            "Epoch 75/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7174\n",
            "Epoch 76/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.7110\n",
            "Epoch 77/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.7062\n",
            "Epoch 78/100\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 0.6917\n",
            "Epoch 79/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6794\n",
            "Epoch 80/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6866\n",
            "Epoch 81/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6815\n",
            "Epoch 82/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6664\n",
            "Epoch 83/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6645\n",
            "Epoch 84/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6566\n",
            "Epoch 85/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6517\n",
            "Epoch 86/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6440\n",
            "Epoch 87/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6456\n",
            "Epoch 88/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6310\n",
            "Epoch 89/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6314\n",
            "Epoch 90/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.6369\n",
            "Epoch 91/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6164\n",
            "Epoch 92/100\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.6134\n",
            "Epoch 93/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6056\n",
            "Epoch 94/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5984\n",
            "Epoch 95/100\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.5934\n",
            "Epoch 96/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5949\n",
            "Epoch 97/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5894\n",
            "Epoch 98/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5896\n",
            "Epoch 99/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5837\n",
            "Epoch 100/100\n",
            "151/151 [==============================] - 1s 5ms/step - loss: 0.5861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f702540ed90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a function that will receive an input text, a model and the number of next words to be predicted. This function will prepare the input text to be fed into the model that will predict the next word.**"
      ],
      "metadata": {
        "id": "glNJ_CktIhJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate text\n",
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "\n",
        "    # Iterate for the number of next words to generate\n",
        "    for _ in range(next_words):\n",
        "\n",
        "        # Convert the seed text to a sequence of tokens using the tokenizer\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "        # Pad the token list using the maximum sequence length\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "        # Use the model to predict the next word\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\n",
        "        # Initialize an empty string to store the output word\n",
        "        output_word = \"\"\n",
        "\n",
        "        # Iterate over the word index of the tokenizer\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "\n",
        "            # Check if the index matches the predicted value\n",
        "            if index == predicted:\n",
        "\n",
        "                # Set the output word to the current word and break out of the loop\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        # Append the output word to the seed text\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    # Return the generated text with title casing\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "vUsP1Oe7HvEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predict your next word...**\n",
        "Output some of your generated text. Add your own words for the model to use and generate from:"
      ],
      "metadata": {
        "id": "vmKY2XVxLYQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text starting with \"the hottest new\" and of length 5 using the provided model and max_sequence_len\n",
        "print(generate_text(\"the hottest new\", 5, model, max_sequence_len))"
      ],
      "metadata": {
        "id": "bCslyF8GK-Ba",
        "outputId": "1f32af9f-7d2c-41d4-f4b8-a51074d2dba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Hottest New Party Of America First A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text starting with \"I am from Bhutan, and I speak\" and of length 8\n",
        "# use the provided model and max_sequence_len\n",
        "print(generate_text(\"I am from Bhutan, and I speak\", 8, model, max_sequence_len))"
      ],
      "metadata": {
        "id": "pCHIRq5sLxfk",
        "outputId": "950e9ef3-8abe-47c2-eab2-45e40b2346d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Am From Bhutan, And I Speak The Hardest Factor Health Together Everyone In Trump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text starting with \"Baby I love\" and of length 3 \n",
        "# using the provided model and max_sequence_len\n",
        "print(generate_text(\"Baby I love\", 3, model, max_sequence_len))"
      ],
      "metadata": {
        "id": "rD9LQGpuNyLT",
        "outputId": "9e9c0734-7dee-4bae-dd62-56680d5d0ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baby I Love Say Bring May\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text starting with \"Your time is limited, so don't waste it\" and of length 4 \n",
        "# using the provided model and max_sequence_len\n",
        "print(generate_text(\"Your time is limited, so don't waste it\", 3, model, max_sequence_len))"
      ],
      "metadata": {
        "id": "1XK_gp8xONC8",
        "outputId": "e1b0fb11-9a7c-4b26-ed08-43762fa32958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Time Is Limited, So Don'T Waste It Good Stars To\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "--------"
      ],
      "metadata": {
        "id": "4FpaWgSjPEx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building an RNN model for Predicting Tweets' Sentiment:**"
      ],
      "metadata": {
        "id": "brLwiknxPHYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the file to the content folder in the colab:"
      ],
      "metadata": {
        "id": "ATHI4Eiha8r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/PacktWorkshops/The-TensorFlow-Workshop/master/Chapter09/Datasets/tweets.csv'\n",
        "filename = 'tweets.csv'\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "ZJfBBS0rO4OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5101cb3d-f8c1-4190-bbee-1b005d5ef8ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tweets.csv', <http.client.HTTPMessage at 0x7fae60286430>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary packages:"
      ],
      "metadata": {
        "id": "SaVohCSlbVr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HptHt-4LbPFE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset directly from the github:"
      ],
      "metadata": {
        "id": "WYpPBirAb5ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/PacktWorkshops/The-TensorFlow-Workshop/master/Chapter09/Datasets/tweets.csv\")\n",
        "\n",
        "# display first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "QH4Qxj97bh8j",
        "outputId": "55ae60fb-f0c3-4222-8e00-ebb7ff3c4b6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc04ea9e-bf1b-4a5f-9a1d-a3df33eff909\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc04ea9e-bf1b-4a5f-9a1d-a3df33eff909')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc04ea9e-bf1b-4a5f-9a1d-a3df33eff909 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc04ea9e-bf1b-4a5f-9a1d-a3df33eff909');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new DataFrame called df that will have only text as **features** and **airline_sentiment** as the target variable:"
      ],
      "metadata": {
        "id": "YAb8h8qwcykj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data[[\"text\", \"airline_sentiment\"]]\n",
        "\n",
        "# remove all rows having sentiment as \"neutral\"\n",
        "df = df[df[\"airline_sentiment\"] != \"neutral\"]\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KbHh_EeIcMyf",
        "outputId": "f881d017-b541-4ba6-dbb6-d2518982651f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text airline_sentiment\n",
              "1  @VirginAmerica plus you've added commercials t...          positive\n",
              "3  @VirginAmerica it's really aggressive to blast...          negative\n",
              "4  @VirginAmerica and it's a really big bad thing...          negative\n",
              "5  @VirginAmerica seriously would pay $30 a fligh...          negative\n",
              "6  @VirginAmerica yes, nearly every time I fly VX...          positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f81395f3-27bb-48e9-8937-08ea43d22d6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f81395f3-27bb-48e9-8937-08ea43d22d6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f81395f3-27bb-48e9-8937-08ea43d22d6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f81395f3-27bb-48e9-8937-08ea43d22d6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform **airline_sentiment** column to numeric type by replacing negative with 0 and positive with 1:"
      ],
      "metadata": {
        "id": "AJeY_AMzdSD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a target variable\n",
        "y = df[\"airline_sentiment\"].map({\"negative\":0, \"positive\":1}).values"
      ],
      "metadata": {
        "id": "Nz8gMmT7c9zd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a features variable\n",
        "X = df[\"text\"]"
      ],
      "metadata": {
        "id": "axIetv0odrtt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Tokenization:"
      ],
      "metadata": {
        "id": "0FM1PuTMeJWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "KaUdZumOd3he"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)"
      ],
      "metadata": {
        "id": "RgibE6E6eexQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit tokenizer on the data X\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "metadata": {
        "id": "2d64b9HZepy2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display vocabulary from the tokenizer\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnalJ_Uyewmf",
        "outputId": "1a512687-3c71-4abd-cc61-6e7c4e5286d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': 1,\n",
              " 'the': 2,\n",
              " 'i': 3,\n",
              " 'a': 4,\n",
              " 'united': 5,\n",
              " 'you': 6,\n",
              " 'for': 7,\n",
              " 'flight': 8,\n",
              " 'and': 9,\n",
              " 'on': 10,\n",
              " 'my': 11,\n",
              " 'usairways': 12,\n",
              " 'americanair': 13,\n",
              " 'is': 14,\n",
              " 'in': 15,\n",
              " 'southwestair': 16,\n",
              " 'of': 17,\n",
              " 'jetblue': 18,\n",
              " 'me': 19,\n",
              " 'your': 20,\n",
              " 'it': 21,\n",
              " 'was': 22,\n",
              " 'not': 23,\n",
              " 'no': 24,\n",
              " 'have': 25,\n",
              " 'at': 26,\n",
              " 'with': 27,\n",
              " 'that': 28,\n",
              " 'this': 29,\n",
              " 'get': 30,\n",
              " 'but': 31,\n",
              " 'be': 32,\n",
              " 'cancelled': 33,\n",
              " 'thanks': 34,\n",
              " 'now': 35,\n",
              " 'service': 36,\n",
              " 'are': 37,\n",
              " 'we': 38,\n",
              " 'from': 39,\n",
              " 'an': 40,\n",
              " 'been': 41,\n",
              " 'just': 42,\n",
              " '2': 43,\n",
              " 'so': 44,\n",
              " 'customer': 45,\n",
              " 'help': 46,\n",
              " 't': 47,\n",
              " 'can': 48,\n",
              " 'time': 49,\n",
              " 'co': 50,\n",
              " 'up': 51,\n",
              " 'hours': 52,\n",
              " 'http': 53,\n",
              " 'do': 54,\n",
              " 'hold': 55,\n",
              " 'they': 56,\n",
              " 'out': 57,\n",
              " 'amp': 58,\n",
              " 'plane': 59,\n",
              " \"i'm\": 60,\n",
              " 'us': 61,\n",
              " 'all': 62,\n",
              " 'will': 63,\n",
              " 'why': 64,\n",
              " 'thank': 65,\n",
              " 'still': 66,\n",
              " 'our': 67,\n",
              " 'delayed': 68,\n",
              " 'what': 69,\n",
              " 'when': 70,\n",
              " 'how': 71,\n",
              " 'one': 72,\n",
              " \"can't\": 73,\n",
              " 'flights': 74,\n",
              " 'call': 75,\n",
              " 'gate': 76,\n",
              " 'hour': 77,\n",
              " 'had': 78,\n",
              " 'flightled': 79,\n",
              " 'back': 80,\n",
              " 'bag': 81,\n",
              " 'if': 82,\n",
              " 'would': 83,\n",
              " 'after': 84,\n",
              " 'has': 85,\n",
              " 'about': 86,\n",
              " 'there': 87,\n",
              " \"it's\": 88,\n",
              " \"don't\": 89,\n",
              " 'as': 90,\n",
              " 'got': 91,\n",
              " 'late': 92,\n",
              " 'phone': 93,\n",
              " 'need': 94,\n",
              " 'please': 95,\n",
              " 'again': 96,\n",
              " '3': 97,\n",
              " 'airline': 98,\n",
              " 'over': 99,\n",
              " 'or': 100,\n",
              " 'like': 101,\n",
              " 'waiting': 102,\n",
              " 'virginamerica': 103,\n",
              " 'today': 104,\n",
              " 'more': 105,\n",
              " 'am': 106,\n",
              " 'guys': 107,\n",
              " 'by': 108,\n",
              " '4': 109,\n",
              " 'great': 110,\n",
              " 'wait': 111,\n",
              " 'u': 112,\n",
              " 'because': 113,\n",
              " 'fly': 114,\n",
              " 'never': 115,\n",
              " 'day': 116,\n",
              " 'trying': 117,\n",
              " \"i've\": 118,\n",
              " 'airport': 119,\n",
              " 'then': 120,\n",
              " 'delay': 121,\n",
              " 'only': 122,\n",
              " '1': 123,\n",
              " 'really': 124,\n",
              " 'minutes': 125,\n",
              " 'even': 126,\n",
              " 'going': 127,\n",
              " 'any': 128,\n",
              " 'should': 129,\n",
              " 'did': 130,\n",
              " '5': 131,\n",
              " 'last': 132,\n",
              " 'people': 133,\n",
              " 'way': 134,\n",
              " 'bags': 135,\n",
              " 'weather': 136,\n",
              " 'were': 137,\n",
              " 'good': 138,\n",
              " 'know': 139,\n",
              " 'agent': 140,\n",
              " 'very': 141,\n",
              " 'off': 142,\n",
              " 'home': 143,\n",
              " 'make': 144,\n",
              " 'told': 145,\n",
              " 'luggage': 146,\n",
              " 'another': 147,\n",
              " 'here': 148,\n",
              " 'worst': 149,\n",
              " 'go': 150,\n",
              " 'flying': 151,\n",
              " 'ever': 152,\n",
              " 'lost': 153,\n",
              " 'than': 154,\n",
              " 'seat': 155,\n",
              " 'w': 156,\n",
              " 'change': 157,\n",
              " 'check': 158,\n",
              " 'them': 159,\n",
              " 'take': 160,\n",
              " 'want': 161,\n",
              " 'hrs': 162,\n",
              " 'due': 163,\n",
              " 'crew': 164,\n",
              " 'getting': 165,\n",
              " 'first': 166,\n",
              " 'days': 167,\n",
              " 'flighted': 168,\n",
              " 'work': 169,\n",
              " 'someone': 170,\n",
              " 'baggage': 171,\n",
              " 'much': 172,\n",
              " 'love': 173,\n",
              " 'too': 174,\n",
              " 'tomorrow': 175,\n",
              " 'made': 176,\n",
              " 'experience': 177,\n",
              " \"that's\": 178,\n",
              " 'response': 179,\n",
              " 'new': 180,\n",
              " 'ticket': 181,\n",
              " 'being': 182,\n",
              " 'see': 183,\n",
              " 'yes': 184,\n",
              " 'could': 185,\n",
              " 'two': 186,\n",
              " 'sitting': 187,\n",
              " 'their': 188,\n",
              " 'through': 189,\n",
              " 'next': 190,\n",
              " 'other': 191,\n",
              " 'she': 192,\n",
              " 'min': 193,\n",
              " 'staff': 194,\n",
              " 'customers': 195,\n",
              " 'bad': 196,\n",
              " 'travel': 197,\n",
              " \"didn't\": 198,\n",
              " 'before': 199,\n",
              " 'let': 200,\n",
              " 'email': 201,\n",
              " 'who': 202,\n",
              " 'better': 203,\n",
              " 'line': 204,\n",
              " 'seats': 205,\n",
              " 'best': 206,\n",
              " 'trip': 207,\n",
              " 'number': 208,\n",
              " 'aa': 209,\n",
              " 'problems': 210,\n",
              " 'said': 211,\n",
              " 'her': 212,\n",
              " 'online': 213,\n",
              " 'right': 214,\n",
              " '10': 215,\n",
              " 'since': 216,\n",
              " 'stuck': 217,\n",
              " 'times': 218,\n",
              " '30': 219,\n",
              " 'jfk': 220,\n",
              " 'some': 221,\n",
              " 'long': 222,\n",
              " 'flightr': 223,\n",
              " \"won't\": 224,\n",
              " 'agents': 225,\n",
              " 'already': 226,\n",
              " 'miss': 227,\n",
              " \"doesn't\": 228,\n",
              " 'nothing': 229,\n",
              " 'boarding': 230,\n",
              " \"you're\": 231,\n",
              " 'where': 232,\n",
              " 'well': 233,\n",
              " 'give': 234,\n",
              " 'issue': 235,\n",
              " 'care': 236,\n",
              " 'system': 237,\n",
              " '6': 238,\n",
              " 'passengers': 239,\n",
              " 'website': 240,\n",
              " 'sure': 241,\n",
              " 'book': 242,\n",
              " 'connection': 243,\n",
              " 'booked': 244,\n",
              " 'tried': 245,\n",
              " 'hotel': 246,\n",
              " 'rude': 247,\n",
              " 'left': 248,\n",
              " 'find': 249,\n",
              " 'dm': 250,\n",
              " 'sent': 251,\n",
              " 'yet': 252,\n",
              " 'same': 253,\n",
              " 'does': 254,\n",
              " 'night': 255,\n",
              " 'delays': 256,\n",
              " 'called': 257,\n",
              " 'missed': 258,\n",
              " 'into': 259,\n",
              " 'refund': 260,\n",
              " 'keep': 261,\n",
              " 'tonight': 262,\n",
              " 'flt': 263,\n",
              " 'airlines': 264,\n",
              " \"i'll\": 265,\n",
              " 'rebooked': 266,\n",
              " 'says': 267,\n",
              " 'miles': 268,\n",
              " 'put': 269,\n",
              " 'mins': 270,\n",
              " 'morning': 271,\n",
              " 'reservation': 272,\n",
              " 'dfw': 273,\n",
              " 'he': 274,\n",
              " 'issues': 275,\n",
              " 'awesome': 276,\n",
              " 'info': 277,\n",
              " 'think': 278,\n",
              " 'hope': 279,\n",
              " 'nice': 280,\n",
              " 'pay': 281,\n",
              " 'air': 282,\n",
              " 'down': 283,\n",
              " 'working': 284,\n",
              " 'booking': 285,\n",
              " 'finally': 286,\n",
              " 'tell': 287,\n",
              " 'ago': 288,\n",
              " 'rebook': 289,\n",
              " 'use': 290,\n",
              " 'lax': 291,\n",
              " 'anything': 292,\n",
              " 'also': 293,\n",
              " 'wifi': 294,\n",
              " 'its': 295,\n",
              " '20': 296,\n",
              " 'every': 297,\n",
              " 'anyone': 298,\n",
              " 'until': 299,\n",
              " \"what's\": 300,\n",
              " 'appreciate': 301,\n",
              " 'free': 302,\n",
              " 'done': 303,\n",
              " 'missing': 304,\n",
              " 'week': 305,\n",
              " 'having': 306,\n",
              " 'business': 307,\n",
              " 'helpful': 308,\n",
              " 'terrible': 309,\n",
              " 'answer': 310,\n",
              " 'dca': 311,\n",
              " 'phl': 312,\n",
              " 'making': 313,\n",
              " 'always': 314,\n",
              " 'person': 315,\n",
              " 'say': 316,\n",
              " 'sfo': 317,\n",
              " 'able': 318,\n",
              " 'problem': 319,\n",
              " '8': 320,\n",
              " 'fail': 321,\n",
              " 'checked': 322,\n",
              " 'board': 323,\n",
              " 'team': 324,\n",
              " 'disappointed': 325,\n",
              " 'without': 326,\n",
              " 'fix': 327,\n",
              " '7': 328,\n",
              " 'credit': 329,\n",
              " 'delta': 330,\n",
              " 'class': 331,\n",
              " 'rep': 332,\n",
              " 'voucher': 333,\n",
              " 'speak': 334,\n",
              " 'which': 335,\n",
              " 'update': 336,\n",
              " 'amazing': 337,\n",
              " 'ord': 338,\n",
              " 'yesterday': 339,\n",
              " 'ridiculous': 340,\n",
              " 'almost': 341,\n",
              " 'thx': 342,\n",
              " 'paid': 343,\n",
              " 'understand': 344,\n",
              " 'unacceptable': 345,\n",
              " 'attendant': 346,\n",
              " 'early': 347,\n",
              " \"couldn't\": 348,\n",
              " 'come': 349,\n",
              " 'app': 350,\n",
              " 'leave': 351,\n",
              " 'extra': 352,\n",
              " 'hung': 353,\n",
              " 'happy': 354,\n",
              " 'money': 355,\n",
              " 'available': 356,\n",
              " 'sorry': 357,\n",
              " 'many': 358,\n",
              " 'claim': 359,\n",
              " \"isn't\": 360,\n",
              " '15': 361,\n",
              " 'look': 362,\n",
              " 'pilot': 363,\n",
              " 'poor': 364,\n",
              " \"haven't\": 365,\n",
              " 'ewr': 366,\n",
              " 'talk': 367,\n",
              " 'horrible': 368,\n",
              " 'stop': 369,\n",
              " 'full': 370,\n",
              " 'planes': 371,\n",
              " 'tarmac': 372,\n",
              " 'employees': 373,\n",
              " '45': 374,\n",
              " 'least': 375,\n",
              " 'stranded': 376,\n",
              " \"wasn't\": 377,\n",
              " 'everyone': 378,\n",
              " 'clt': 379,\n",
              " 'status': 380,\n",
              " 'upgrade': 381,\n",
              " 'tickets': 382,\n",
              " 'job': 383,\n",
              " 'took': 384,\n",
              " 'ok': 385,\n",
              " '': 386,\n",
              " 'ground': 387,\n",
              " 'seriously': 388,\n",
              " \"we're\": 389,\n",
              " 'while': 390,\n",
              " 'supposed': 391,\n",
              " 'company': 392,\n",
              " 'gt': 393,\n",
              " 'though': 394,\n",
              " 'connecting': 395,\n",
              " 'different': 396,\n",
              " 'southwest': 397,\n",
              " 'departure': 398,\n",
              " 'try': 399,\n",
              " 'actually': 400,\n",
              " 'bos': 401,\n",
              " 'calling': 402,\n",
              " 'contact': 403,\n",
              " 'looking': 404,\n",
              " 'instead': 405,\n",
              " '1st': 406,\n",
              " 'site': 407,\n",
              " 'year': 408,\n",
              " '40': 409,\n",
              " 'family': 410,\n",
              " 'found': 411,\n",
              " 'ur': 412,\n",
              " 'half': 413,\n",
              " 'most': 414,\n",
              " '50': 415,\n",
              " 'landed': 416,\n",
              " 'taking': 417,\n",
              " 'received': 418,\n",
              " 'oh': 419,\n",
              " 'frustrated': 420,\n",
              " 'open': 421,\n",
              " 'vacation': 422,\n",
              " 'three': 423,\n",
              " 'weeks': 424,\n",
              " 'food': 425,\n",
              " 'follow': 426,\n",
              " 'wrong': 427,\n",
              " 'hr': 428,\n",
              " 'gave': 429,\n",
              " 'via': 430,\n",
              " 'wife': 431,\n",
              " 'doing': 432,\n",
              " 'boston': 433,\n",
              " 'earlier': 434,\n",
              " 'twitter': 435,\n",
              " 'something': 436,\n",
              " 'bc': 437,\n",
              " 'far': 438,\n",
              " 'big': 439,\n",
              " 'mechanical': 440,\n",
              " 'broken': 441,\n",
              " '24': 442,\n",
              " 'denver': 443,\n",
              " 'reason': 444,\n",
              " '11': 445,\n",
              " '9': 446,\n",
              " 'desk': 447,\n",
              " 'send': 448,\n",
              " 'twice': 449,\n",
              " 'away': 450,\n",
              " 'reply': 451,\n",
              " 'his': 452,\n",
              " 'direct': 453,\n",
              " 'worse': 454,\n",
              " 'past': 455,\n",
              " 'maybe': 456,\n",
              " 'pass': 457,\n",
              " 'enough': 458,\n",
              " 'sit': 459,\n",
              " 'needs': 460,\n",
              " 'b': 461,\n",
              " 'those': 462,\n",
              " 'point': 463,\n",
              " 'might': 464,\n",
              " 'dallas': 465,\n",
              " 'makes': 466,\n",
              " 'asked': 467,\n",
              " 'tweet': 468,\n",
              " 'name': 469,\n",
              " 'option': 470,\n",
              " 'once': 471,\n",
              " 'went': 472,\n",
              " 'charge': 473,\n",
              " 'old': 474,\n",
              " '25': 475,\n",
              " 'changed': 476,\n",
              " 'both': 477,\n",
              " 'less': 478,\n",
              " 'message': 479,\n",
              " 'chicago': 480,\n",
              " 'runway': 481,\n",
              " 'little': 482,\n",
              " 'thing': 483,\n",
              " 'nyc': 484,\n",
              " 'san': 485,\n",
              " '800': 486,\n",
              " 'stay': 487,\n",
              " 'waited': 488,\n",
              " 'lot': 489,\n",
              " 'saying': 490,\n",
              " 'leaving': 491,\n",
              " 'awful': 492,\n",
              " '200': 493,\n",
              " 'things': 494,\n",
              " 'return': 495,\n",
              " 'around': 496,\n",
              " 'seems': 497,\n",
              " 'fee': 498,\n",
              " 'lack': 499,\n",
              " 'american': 500,\n",
              " 'frustrating': 501,\n",
              " 'reservations': 502,\n",
              " 'cool': 503,\n",
              " 'hey': 504,\n",
              " 'hard': 505,\n",
              " 'account': 506,\n",
              " 'longer': 507,\n",
              " 'sucks': 508,\n",
              " \"i'd\": 509,\n",
              " 'telling': 510,\n",
              " 'real': 511,\n",
              " 'phx': 512,\n",
              " 'card': 513,\n",
              " 'car': 514,\n",
              " 'houston': 515,\n",
              " 'charlotte': 516,\n",
              " 'show': 517,\n",
              " 'destination': 518,\n",
              " 'given': 519,\n",
              " 'airways': 520,\n",
              " 'arrived': 521,\n",
              " 'during': 522,\n",
              " 'him': 523,\n",
              " 'together': 524,\n",
              " 'looks': 525,\n",
              " 'calls': 526,\n",
              " 'guess': 527,\n",
              " 'attendants': 528,\n",
              " 'these': 529,\n",
              " \"you've\": 530,\n",
              " 'feel': 531,\n",
              " 'sat': 532,\n",
              " 'minute': 533,\n",
              " 'snow': 534,\n",
              " 'coming': 535,\n",
              " 'cust': 536,\n",
              " 'own': 537,\n",
              " 'else': 538,\n",
              " 'thru': 539,\n",
              " 'maintenance': 540,\n",
              " 're': 541,\n",
              " 'start': 542,\n",
              " 'such': 543,\n",
              " 'vegas': 544,\n",
              " 'link': 545,\n",
              " 'pls': 546,\n",
              " 'joke': 547,\n",
              " '12': 548,\n",
              " \"we've\": 549,\n",
              " 'iah': 550,\n",
              " 'counting': 551,\n",
              " 'heard': 552,\n",
              " 'fll': 553,\n",
              " 'policy': 554,\n",
              " 'landing': 555,\n",
              " 'suck': 556,\n",
              " 'row': 557,\n",
              " 'loyal': 558,\n",
              " \"there's\": 559,\n",
              " 'den': 560,\n",
              " 'may': 561,\n",
              " 'happened': 562,\n",
              " 'options': 563,\n",
              " 'add': 564,\n",
              " 'member': 565,\n",
              " 'c': 566,\n",
              " 'error': 567,\n",
              " 'philly': 568,\n",
              " 'apology': 569,\n",
              " 'life': 570,\n",
              " 'spent': 571,\n",
              " 'reflight': 572,\n",
              " \"wouldn't\": 573,\n",
              " 'information': 574,\n",
              " 'plus': 575,\n",
              " 'human': 576,\n",
              " 'scheduled': 577,\n",
              " 'offer': 578,\n",
              " 'cost': 579,\n",
              " 'newark': 580,\n",
              " 'glad': 581,\n",
              " 'using': 582,\n",
              " 'soon': 583,\n",
              " 'believe': 584,\n",
              " 'hear': 585,\n",
              " 'communication': 586,\n",
              " 'reach': 587,\n",
              " 'busy': 588,\n",
              " 'iad': 589,\n",
              " 'end': 590,\n",
              " 'lga': 591,\n",
              " '100': 592,\n",
              " 'assistance': 593,\n",
              " 'cannot': 594,\n",
              " 'each': 595,\n",
              " 'terminal': 596,\n",
              " 'fleek': 597,\n",
              " 'everything': 598,\n",
              " 'im': 599,\n",
              " 'lose': 600,\n",
              " 'quick': 601,\n",
              " 'boarded': 602,\n",
              " 'ua': 603,\n",
              " 'arrive': 604,\n",
              " 'needed': 605,\n",
              " 'changes': 606,\n",
              " 'usair': 607,\n",
              " 'wow': 608,\n",
              " 'few': 609,\n",
              " 'room': 610,\n",
              " 'complaint': 611,\n",
              " 'jet': 612,\n",
              " 'expect': 613,\n",
              " 'swa': 614,\n",
              " 'flew': 615,\n",
              " 'las': 616,\n",
              " 'paying': 617,\n",
              " 'kids': 618,\n",
              " 'helping': 619,\n",
              " 'entire': 620,\n",
              " 'computer': 621,\n",
              " 'guy': 622,\n",
              " 'unitedairlines': 623,\n",
              " \"they're\": 624,\n",
              " 'counter': 625,\n",
              " \"aren't\": 626,\n",
              " 'pick': 627,\n",
              " 'miami': 628,\n",
              " \"fleet's\": 629,\n",
              " 'confirmation': 630,\n",
              " 'forward': 631,\n",
              " 'wanted': 632,\n",
              " 'whole': 633,\n",
              " 'used': 634,\n",
              " 'blue': 635,\n",
              " '2nd': 636,\n",
              " 'process': 637,\n",
              " 'dc': 638,\n",
              " 'mean': 639,\n",
              " 'passenger': 640,\n",
              " 'city': 641,\n",
              " 'wtf': 642,\n",
              " 'hoping': 643,\n",
              " 'empty': 644,\n",
              " 'non': 645,\n",
              " 'form': 646,\n",
              " 'idea': 647,\n",
              " 'automated': 648,\n",
              " 'holding': 649,\n",
              " 'pretty': 650,\n",
              " 'beyond': 651,\n",
              " 'checking': 652,\n",
              " 'run': 653,\n",
              " 'bwi': 654,\n",
              " 'situation': 655,\n",
              " 'sw': 656,\n",
              " 'fine': 657,\n",
              " 'respond': 658,\n",
              " 'pilots': 659,\n",
              " 'place': 660,\n",
              " 'years': 661,\n",
              " 'chance': 662,\n",
              " 'thought': 663,\n",
              " 'flighting': 664,\n",
              " 'rather': 665,\n",
              " 'sleep': 666,\n",
              " 'standby': 667,\n",
              " 'fault': 668,\n",
              " 'deal': 669,\n",
              " 'tv': 670,\n",
              " 'customerservice': 671,\n",
              " 'rt': 672,\n",
              " 'cant': 673,\n",
              " 'points': 674,\n",
              " 'wish': 675,\n",
              " 'request': 676,\n",
              " 'supervisor': 677,\n",
              " 'upset': 678,\n",
              " 'yeah': 679,\n",
              " 'taken': 680,\n",
              " 'friend': 681,\n",
              " 'mco': 682,\n",
              " 'moved': 683,\n",
              " 'completely': 684,\n",
              " 'buy': 685,\n",
              " 'offered': 686,\n",
              " 'handle': 687,\n",
              " 'confirmed': 688,\n",
              " 'treat': 689,\n",
              " 'second': 690,\n",
              " 'updates': 691,\n",
              " 'traveling': 692,\n",
              " 'top': 693,\n",
              " 'case': 694,\n",
              " 'disconnected': 695,\n",
              " 'hi': 696,\n",
              " 'support': 697,\n",
              " 'easy': 698,\n",
              " 'reschedule': 699,\n",
              " 'apparently': 700,\n",
              " 'monday': 701,\n",
              " 'group': 702,\n",
              " 'ask': 703,\n",
              " 'international': 704,\n",
              " 'compensation': 705,\n",
              " 'happen': 706,\n",
              " 'delivered': 707,\n",
              " 'employee': 708,\n",
              " 'hate': 709,\n",
              " 'lt': 710,\n",
              " 'mia': 711,\n",
              " 'either': 712,\n",
              " 'provide': 713,\n",
              " 'question': 714,\n",
              " 'possible': 715,\n",
              " 'carry': 716,\n",
              " 'connections': 717,\n",
              " 'drive': 718,\n",
              " 'months': 719,\n",
              " 'seem': 720,\n",
              " 'asking': 721,\n",
              " 'zero': 722,\n",
              " \"we'll\": 723,\n",
              " 'sunday': 724,\n",
              " 'lol': 725,\n",
              " 'appreciated': 726,\n",
              " 'la': 727,\n",
              " 'friendly': 728,\n",
              " 'world': 729,\n",
              " 'super': 730,\n",
              " 'sad': 731,\n",
              " 'checkin': 732,\n",
              " 'charged': 733,\n",
              " \"shouldn't\": 734,\n",
              " 'club': 735,\n",
              " 'helped': 736,\n",
              " \"y'all\": 737,\n",
              " 'between': 738,\n",
              " 'fees': 739,\n",
              " 'platinum': 740,\n",
              " 'figure': 741,\n",
              " 'fact': 742,\n",
              " 'leg': 743,\n",
              " 'hopefully': 744,\n",
              " 'gets': 745,\n",
              " 'flightlations': 746,\n",
              " 'live': 747,\n",
              " 'kind': 748,\n",
              " 'four': 749,\n",
              " 'bought': 750,\n",
              " 'month': 751,\n",
              " 'flightlation': 752,\n",
              " 'high': 753,\n",
              " 'price': 754,\n",
              " 'future': 755,\n",
              " 'reps': 756,\n",
              " 'despite': 757,\n",
              " 'atl': 758,\n",
              " 'happens': 759,\n",
              " 'extremely': 760,\n",
              " 'clothes': 761,\n",
              " 'means': 762,\n",
              " 'list': 763,\n",
              " 'huge': 764,\n",
              " 'crazy': 765,\n",
              " 'losing': 766,\n",
              " 'destinationdragons': 767,\n",
              " 'answering': 768,\n",
              " 'front': 769,\n",
              " 'tsa': 770,\n",
              " 'fun': 771,\n",
              " 'inconvenience': 772,\n",
              " 'https': 773,\n",
              " 'several': 774,\n",
              " 'shit': 775,\n",
              " 'answers': 776,\n",
              " 'gives': 777,\n",
              " 'sending': 778,\n",
              " 'seen': 779,\n",
              " 'media': 780,\n",
              " 'water': 781,\n",
              " 'f': 782,\n",
              " 'asap': 783,\n",
              " 'giving': 784,\n",
              " 'ny': 785,\n",
              " 'rescheduled': 786,\n",
              " 'came': 787,\n",
              " 'safety': 788,\n",
              " 'purchase': 789,\n",
              " 'spoke': 790,\n",
              " 'address': 791,\n",
              " 'luck': 792,\n",
              " 'details': 793,\n",
              " 'pm': 794,\n",
              " 'fixed': 795,\n",
              " 'unable': 796,\n",
              " 'phones': 797,\n",
              " 'sense': 798,\n",
              " 'multiple': 799,\n",
              " 'switch': 800,\n",
              " 'dont': 801,\n",
              " 'friends': 802,\n",
              " 'rock': 803,\n",
              " 'lots': 804,\n",
              " 'flown': 805,\n",
              " 'gold': 806,\n",
              " 'gonna': 807,\n",
              " 'luv': 808,\n",
              " '1k': 809,\n",
              " 'held': 810,\n",
              " 'kudos': 811,\n",
              " 'load': 812,\n",
              " 'arrival': 813,\n",
              " 'o': 814,\n",
              " 'treated': 815,\n",
              " 'hang': 816,\n",
              " \"hasn't\": 817,\n",
              " 'relations': 818,\n",
              " 'award': 819,\n",
              " 'must': 820,\n",
              " 'totally': 821,\n",
              " 'keeps': 822,\n",
              " 'spend': 823,\n",
              " 'report': 824,\n",
              " 'austin': 825,\n",
              " '': 826,\n",
              " 'set': 827,\n",
              " 'excellent': 828,\n",
              " 'part': 829,\n",
              " 'plans': 830,\n",
              " 'storm': 831,\n",
              " 'complete': 832,\n",
              " 'wonderful': 833,\n",
              " 'aircraft': 834,\n",
              " 'members': 835,\n",
              " 'ready': 836,\n",
              " 'nope': 837,\n",
              " 'original': 838,\n",
              " 'priority': 839,\n",
              " 'ppl': 840,\n",
              " 'lines': 841,\n",
              " 'knew': 842,\n",
              " 'tuesday': 843,\n",
              " 'country': 844,\n",
              " 'under': 845,\n",
              " 'americanairlines': 846,\n",
              " '000': 847,\n",
              " 'cabin': 848,\n",
              " 'probably': 849,\n",
              " 'fare': 850,\n",
              " 'read': 851,\n",
              " 'date': 852,\n",
              " 'overnight': 853,\n",
              " 'matter': 854,\n",
              " 'okay': 855,\n",
              " 'neveragain': 856,\n",
              " 'responding': 857,\n",
              " 'dealing': 858,\n",
              " '1hr': 859,\n",
              " 'myself': 860,\n",
              " 'attitude': 861,\n",
              " 'allow': 862,\n",
              " 'letter': 863,\n",
              " 'gone': 864,\n",
              " 'layover': 865,\n",
              " \"she's\": 866,\n",
              " 'running': 867,\n",
              " 'folks': 868,\n",
              " 'r': 869,\n",
              " 'forced': 870,\n",
              " 'space': 871,\n",
              " 'word': 872,\n",
              " 'explain': 873,\n",
              " 'ice': 874,\n",
              " 'literally': 875,\n",
              " 'control': 876,\n",
              " 'complaints': 877,\n",
              " 'mess': 878,\n",
              " 'excited': 879,\n",
              " 'cause': 880,\n",
              " 'middle': 881,\n",
              " 'kept': 882,\n",
              " 'land': 883,\n",
              " 'absolutely': 884,\n",
              " 'small': 885,\n",
              " 'currently': 886,\n",
              " 'vouchers': 887,\n",
              " 'arriving': 888,\n",
              " 'record': 889,\n",
              " 'goes': 890,\n",
              " 'mine': 891,\n",
              " 'knows': 892,\n",
              " 'however': 893,\n",
              " 'usairwaysfail': 894,\n",
              " 'door': 895,\n",
              " '90': 896,\n",
              " 'choice': 897,\n",
              " 'plan': 898,\n",
              " 'bring': 899,\n",
              " 'hangs': 900,\n",
              " 'yall': 901,\n",
              " 'correct': 902,\n",
              " 'useless': 903,\n",
              " '2015': 904,\n",
              " 'takes': 905,\n",
              " '35': 906,\n",
              " 'closed': 907,\n",
              " 'access': 908,\n",
              " 'center': 909,\n",
              " 'husband': 910,\n",
              " 'learn': 911,\n",
              " 'worked': 912,\n",
              " 'services': 913,\n",
              " 'note': 914,\n",
              " 'lounge': 915,\n",
              " 'ruined': 916,\n",
              " 'bs': 917,\n",
              " 'tag': 918,\n",
              " 'letting': 919,\n",
              " 'worth': 920,\n",
              " 'unfortunately': 921,\n",
              " '75': 922,\n",
              " 'failed': 923,\n",
              " 'nashville': 924,\n",
              " 'none': 925,\n",
              " 'explanation': 926,\n",
              " 'orlando': 927,\n",
              " 'area': 928,\n",
              " 'bna': 929,\n",
              " 'haha': 930,\n",
              " 'cold': 931,\n",
              " 'birthday': 932,\n",
              " 'sign': 933,\n",
              " 'mind': 934,\n",
              " 'ride': 935,\n",
              " 'anyway': 936,\n",
              " 'web': 937,\n",
              " 'drink': 938,\n",
              " 'shows': 939,\n",
              " 'window': 940,\n",
              " \"let's\": 941,\n",
              " 'happening': 942,\n",
              " 'mileage': 943,\n",
              " 'course': 944,\n",
              " 'svc': 945,\n",
              " 'overhead': 946,\n",
              " 'unhelpful': 947,\n",
              " 'caused': 948,\n",
              " 'drop': 949,\n",
              " 'unhappy': 950,\n",
              " 's': 951,\n",
              " 'resolved': 952,\n",
              " 'rdu': 953,\n",
              " 'changing': 954,\n",
              " 'volume': 955,\n",
              " '3rd': 956,\n",
              " 'entertainment': 957,\n",
              " 'schedule': 958,\n",
              " 'flyer': 959,\n",
              " 'page': 960,\n",
              " 'lady': 961,\n",
              " 'btw': 962,\n",
              " 'friday': 963,\n",
              " 'filed': 964,\n",
              " 'behind': 965,\n",
              " 'story': 966,\n",
              " 'feb': 967,\n",
              " 'dropped': 968,\n",
              " 'tix': 969,\n",
              " 'yr': 970,\n",
              " 'short': 971,\n",
              " 'started': 972,\n",
              " \"weren't\": 973,\n",
              " 'others': 974,\n",
              " 'total': 975,\n",
              " 'anymore': 976,\n",
              " '22': 977,\n",
              " 'works': 978,\n",
              " 'captain': 979,\n",
              " 'tired': 980,\n",
              " 'move': 981,\n",
              " 'major': 982,\n",
              " '2hrs': 983,\n",
              " 'airplane': 984,\n",
              " 'screwed': 985,\n",
              " 'talked': 986,\n",
              " 'cover': 987,\n",
              " 'fucking': 988,\n",
              " 'except': 989,\n",
              " 'social': 990,\n",
              " 'bumped': 991,\n",
              " 'safe': 992,\n",
              " 'acceptable': 993,\n",
              " 'worries': 994,\n",
              " 'trouble': 995,\n",
              " 'absolute': 996,\n",
              " 'notification': 997,\n",
              " 'stuff': 998,\n",
              " 'route': 999,\n",
              " \"he's\": 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output vocabulary above, you can see the word to has been assigned the index 1, the is assigned 2, and so on. **You can use it to map the raw text into a numerical version of it**."
      ],
      "metadata": {
        "id": "0MoDIE-8fOOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the vocab_size variable to contain the length of the tokenizer vocabulary plus an additional character that will be used for unknown words:"
      ],
      "metadata": {
        "id": "APj7JrE-fYqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "HuZaIwroe-Jv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform the raw text from X to an encoded version using the vocabulary from tokenizer."
      ],
      "metadata": {
        "id": "o-jlq7ftfw5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_tweets = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "PALw-bWpfv3T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad encoded_tweets with 280 at the end for a maximum of 280 characters."
      ],
      "metadata": {
        "id": "B9QJgzSagGty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tweets = pad_sequences(encoded_tweets, maxlen=280, padding=\"post\")\n",
        "\n",
        "# print the shape of padded_tweets\n",
        "padded_tweets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dByUz8DBgAxy",
        "outputId": "b2787aa3-5a58-425c-871c-2a44cd05670e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11541, 280)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly permute the indices of padded_tweets\n",
        "indices = np.random.permutation(padded_tweets.shape[0])"
      ],
      "metadata": {
        "id": "4GEIv3pMgjeI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store training & testing data idx\n",
        "train_idx = indices[:10000]\n",
        "test_idx = indices[10000:]"
      ],
      "metadata": {
        "id": "2IJDYiFPgzj6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting dataset into Training and testing sets:"
      ],
      "metadata": {
        "id": "zMyr9_IahK9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = padded_tweets[train_idx]\n",
        "X_test = padded_tweets[test_idx]\n",
        "\n",
        "y_train = y[train_idx]\n",
        "y_test = y[test_idx]"
      ],
      "metadata": {
        "id": "EQL7GEivhHhw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the RNN model**"
      ],
      "metadata": {
        "id": "weXX-jJNhoQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding"
      ],
      "metadata": {
        "id": "4Iv1OBSNhj3R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the sequential model\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "51oYlkSth6R8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add an Embedding layer with length of the vocabulary, the length of embedding layer and input length\n",
        "model.add(Embedding(vocab_size, 300, input_length=280))\n",
        "\n",
        "# add LSTM layer with 50 units\n",
        "model.add(LSTM(units=50, activation=\"relu\", return_sequences=True))\n",
        "# add Dropout layer with a rate of 20% to prevent overfitting\n",
        "\n",
        "# add another LSTM layer with 100 units\n",
        "model.add(LSTM(units=100, activation=\"relu\"))\n",
        "# add another Dropout with a rate of 20%\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# add final Dense layer as output with sigmoid activation function\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZXwBQCbiFpq",
        "outputId": "f70bb541-435e-4460-d8b0-c5db2d4a09a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# displayt summary of the model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkZZBLuxj3cr",
        "outputId": "8275b7eb-8f6c-4fe7-a67d-2daddb7a293f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 280, 300)          3970200   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 280, 50)           70200     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 100)               60400     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,100,901\n",
            "Trainable params: 4,100,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model with appropriate loss function, accuracy metrics, and optimizer:"
      ],
      "metadata": {
        "id": "jOl61baIkTcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "xiBRPInMj8_e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the RNN model to the training data:"
      ],
      "metadata": {
        "id": "XjDsdUweknhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=2,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIAa4S9Gkii-",
        "outputId": "404487eb-7b46-4ae0-cf62-407d076d1fb2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "313/313 [==============================] - 369s 1s/step - loss: nan - accuracy: 0.7951\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 321s 1s/step - loss: nan - accuracy: 0.7960\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadc1897040>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   You can try to improve this by removing stop words \n",
        "or extremely frequent words such as **the** and **a** that don't really help to assess the sentiment of a tweet and see if you can achieve the same performance on the testing set.\n",
        "\n",
        "*   You can deduce that the model can correctly predict almost 80% of the sentiments for the tweets in the training data."
      ],
      "metadata": {
        "id": "aFCiw3E9lJ-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------\n",
        "\n",
        "-------"
      ],
      "metadata": {
        "id": "iL1bsqB7oWIP"
      }
    }
  ]
}